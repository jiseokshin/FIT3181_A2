{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/jiseokshin/FIT3181_A2/blob/main/FIT3181_DeepLearning_Assignment2_Official%5BMain%5D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qEHyseHxA8q4"
   },
   "source": [
    "# <font color=\"#0b486b\">  FIT3181: Deep Learning (2025) - Assignment 2 (Section I)</font>\n",
    "***\n",
    "*CE/Lecturer (Clayton):*  **Dr Trung Le** | trunglm@monash.edu <br/>\n",
    "*Lecturer (Clayton):* **A/Prof Zongyuan Ge** | zongyuan.ge@monash.edu <br/>\n",
    "*Lecturer (Malaysia):*  **Dr Arghya Pal** | arghya.pal@monash.edu <br/>\n",
    " <br/>\n",
    "*Head Tutor 3181:*  **Ms Ruda Nie H** |  \\[RudaNie.H@monash.edu \\] <br/>\n",
    "*Head Tutor 5215:*  **Ms Leila Mahmoodi** |  \\[leila.mahmoodi@monash.edu \\]\n",
    "\n",
    "<br/> <br/>\n",
    "Faculty of Information Technology, Monash University, Australia\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QqMi8gdDBD1L"
   },
   "source": [
    "# <font color=\"#0b486b\">  Student Information</font>\n",
    "***\n",
    "Surname: **Shin**  <br/>\n",
    "Firstname: **Jiseok**    <br/>\n",
    "Student ID: **[33095310]**    <br/>\n",
    "Email: **[jshi0072@student.monash.edu]**    <br/>\n",
    "Your tutorial time: **[Thursday 2pm-5pm]**    <br/>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7e8EwkVtGva7"
   },
   "source": [
    "# <font color=\"0b486b\">Assignment 2 \u2013 Deep Learning for Sequential Data</font>\n",
    "### Due: <font color=\"red\">11:55pm Sunday, 26 October 2025</font> (FIT3181)\n",
    "\n",
    "#### <font color=\"red\">Important note:</font> This is an **individual** assignment. It contributes **20%** to your final mark. Read the assignment instructions carefully."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PF8vqRzTCEsm"
   },
   "source": [
    "## <font color=\"#0b486b\">Assignment 2's Organization</font>\n",
    "This assignment 2 has two (2) sections:\n",
    "- Section 1: Fundamentals of RNNs (10 marks).\n",
    "- Section 2: Deep Learning for Sequential Data (90 marks). This section is further divided into 4 parts.\n",
    "\n",
    "The assignment 2 is organized in three (3) notebooks.\n",
    "- Notebook 1 (this notebook) [Total: 30 marks] includes Section 1 as well as Part 1 and Part 2 of Section 2.\n",
    "- Notebook 2 ([link](https://colab.research.google.com/drive/1m0mh9Mk4-AKEhgAHRwQdl5mc0x7SF7Tv?usp=sharing)) [Total: 40 marks] includes Part 3 of Section 2.\n",
    "- Notebook 3 ([link](https://colab.research.google.com/drive/1JfMZeCkkvjZ5LvKNV-UnR10pl-RogMgF?usp=sharing)) [Total: 30 marks] includes Part 4 of Section 2.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WnlGo-hGBvlO"
   },
   "source": [
    "## <font color=\"#0b486b\">What to submit</font>\n",
    "\n",
    "This assignment is to be completed individually and submitted to Moodle unit site. **By the due date, you are required to submit one  <font color=\"red; font-weight:bold\">single zip file, named 33095310_assignment02_solution.zip</font> where `xxx` is your student ID, to the corresponding Assignment (Dropbox) in Moodle**. You can use Google Colab to do Assignment 2 but you need to save it to an `*.ipynb` file to submit to the unit Moodle.\n",
    "\n",
    "**More importantly, if you use Google Colab to do this assignment, you need to first make a copy of this notebook on your Google drive**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZVGeGjkzn4RG"
   },
   "source": [
    "***For example, if your student ID is <font color=\"red; font-weight:bold\">12356</font>, then gather all of your assignment solutions to a folder, create a zip file named <font color=\"red; font-weight:bold\">123456_assignment02_solution.zip</font> and submit this file.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u3J6gGAMn44Z"
   },
   "source": [
    "Within this zip folder, you **must** submit the following files <u>for each part</u>:\n",
    "1.\t**`FIT3181_DeepLearning_Assignment2_Official[Main].ipynb`**:  this is your Python notebook solution source file.\n",
    "1.\t**`FIT3181_DeepLearning_Assignment2_Official[Main].html`**: this is the output of your Python notebook solution *exported* in HTML format.\n",
    "1. **`FIT3181_DeepLearning_Assignment2_Official[RNNs].ipynb`**\n",
    "1. **`FIT3181_DeepLearning_Assignment2_Official[RNNs].html`**\n",
    "1. **`FIT3181_DeepLearning_Assignment2_Official[Transformers].ipynb`**\n",
    "1. **`FIT3181_DeepLearning_Assignment2_Official[Transformers].html`**\n",
    "1.\tAny **extra files or folder** needed to complete your assignment (e.g., images used in your answers).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LsB3OmMxB4Dh"
   },
   "source": [
    "## Section 1: Fundamentals in RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c83ea5R9nh_y"
   },
   "source": [
    "You need to **manually** implement a multi-timestep Recurrent Neural Network that can take an input as a 3D tensor `[batch_size, seq_len, input_size]` for a classification task.\n",
    "\n",
    "<div style=\"text-align: right\"><font color=\"red\">[Total: 10 marks]</font></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "OzH6RTIjExy2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1183dae10>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "torch.set_printoptions(sci_mode=False, precision=4)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yKlCx1D3rczS"
   },
   "source": [
    "We declare the relevant variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "C77pPiGBA9IJ"
   },
   "outputs": [],
   "source": [
    "input_size = 5\n",
    "seq_len = 4\n",
    "batch_size = 8\n",
    "hidden_size = 3\n",
    "num_classes = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A10tCeyKrkUt"
   },
   "source": [
    "We create random inputs (i.e., `inputs`) and random labels (i.e., `random_labels`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ybfqj-wBEu0H",
    "outputId": "0387f520-f380-47e0-b7e2-c0107d18d77b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 5])\n",
      "tensor([1, 2, 2, 2, 2, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.randn(batch_size, seq_len, input_size)\n",
    "random_labels = torch.randint(0, num_classes, (batch_size,))\n",
    "print(inputs.shape)\n",
    "print(random_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I7ABTPhyr6wa"
   },
   "source": [
    "(1) In what follows, we need to declare the model parameters, which include the matrices $U$ (``[input_size, hidden_size]``), W (``[hidden_size, hidden_size]``), $V$ (``[hidden_size, num_classes]``) and the biases $b$ and $c$ for the hidden states and logits respectively.\n",
    "\n",
    "<div style=\"text-align: right\"><font color=\"red\">[2 marks]</font></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "qzlZtACzsbSR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U: torch.Size([5, 3]) W: torch.Size([3, 3]) b: torch.Size([3]) V: torch.Size([3, 3]) c: torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "#Insert your code here\n",
    "U = torch.nn.Parameter(torch.randn(input_size, hidden_size) * (2/hidden_size)**0.5)\n",
    "W = torch.nn.Parameter(torch.randn(hidden_size, hidden_size) * (2/hidden_size)**0.5)\n",
    "b = torch.nn.Parameter(torch.zeros(hidden_size))\n",
    "V = torch.nn.Parameter(torch.randn(hidden_size, num_classes) * (2/hidden_size)**0.5)\n",
    "c = torch.nn.Parameter(torch.zeros(num_classes))\n",
    "\n",
    "\n",
    "params = [U, W, b, V, c]\n",
    "for p in params:\n",
    "    p.requires_grad_(True)\n",
    "    \n",
    "print(\"U:\", U.shape, \"W:\", W.shape, \"b:\", b.shape, \"V:\", V.shape, \"c:\", c.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MW_gal7Us9fK"
   },
   "source": [
    "(2) Next you need to write the code to compute `hiddens` which is a 3D tensor of the shape ``[batch_size, seq_len, hidden_size]`` using the formula of the simple/standard RNN cells. You can freely modify the code below.\n",
    "\n",
    "<div style=\"text-align: right\"><font color=\"red\">[2 marks]</font></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "KwxqdXkTtaea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 3])\n",
      "tensor([[ 0.9996, -0.9977, -0.9888],\n",
      "        [-0.9293,  0.9716, -0.8190]], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#Initialize hiddens for update.\n",
    "hiddens = torch.zeros(batch_size, seq_len, hidden_size)\n",
    "\n",
    "#Insert your code here\n",
    "h_prev = torch.zeros(batch_size, hidden_size)\n",
    "for t in range(seq_len):\n",
    "    x_t = inputs[:, t, :]                               # (batch_size, input_size)\n",
    "    h_t = torch.tanh(x_t @ U + h_prev @ W + b)          # (batch_size, hidden_size)\n",
    "    hiddens[:, t, :] = h_t\n",
    "    h_prev = h_t\n",
    "\n",
    "print(hiddens.shape)\n",
    "print(hiddens[:2, -1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sC3gaFvLtyUW"
   },
   "source": [
    "(3) In what follows, you need to write the code to compute the logits based on the last hidden state (``[batch_size, hidden_size]``) of hiddens.\n",
    "\n",
    "<div style=\"text-align: right\"><font color=\"red\">[1 mark]</font></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Psr-vrw8uCMN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits.shape: torch.Size([8, 3])\n",
      "tensor([[ 1.3990,  0.2307,  0.7709],\n",
      "        [-1.1064,  0.1209,  0.8236],\n",
      "        [-0.6812, -0.2259,  0.7966],\n",
      "        [-1.2046, -0.2168, -0.7344],\n",
      "        [-1.2082, -0.4272, -0.8664],\n",
      "        [-1.1872, -0.2159, -0.7938],\n",
      "        [-0.2276,  0.2471, -0.3473],\n",
      "        [-1.2993, -0.3404, -0.8288]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "h_last = hiddens[:, -1, :]\n",
    "logits = h_last @ V + c       \n",
    "print(\"logits.shape:\", logits.shape)\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3DEJQQz9uKFb"
   },
   "source": [
    "(4) Write the code to compute the cross-entropy loss by comparing the logits to the labels. You can use PyTorch's built-in loss function.\n",
    "\n",
    "<div style=\"text-align: right\"><font color=\"red\">[1 mark]</font></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Gyy7lbacuWPR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.206323504447937\n",
      "tensor(1.2063, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#Insert your code here\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "loss = criterion(logits, random_labels)\n",
    "print(\"loss:\", loss.item())\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RVt-977bumET"
   },
   "source": [
    "(5) Next, you need to do back-propagation to compute the gradients of the loss w.r.t. the model parameters. You can use PyTorch's built-in method to compute the gradients.\n",
    "\n",
    "<div style=\"text-align: right\"><font color=\"red\">[2 marks]</font></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "HSpeFroAu6oO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U.grad norm: 0.344451\n",
      "W.grad norm: 0.275753\n",
      "b.grad norm: 0.142836\n",
      "V.grad norm: 0.791970\n",
      "c.grad norm: 0.330426\n"
     ]
    }
   ],
   "source": [
    "#Insert your code here\n",
    "\n",
    "# Zero grads (in case this cell is re-run)\n",
    "for p in params:\n",
    "    if p.grad is not None:\n",
    "        p.grad.zero_()\n",
    "\n",
    "# Recompute forward (so graph is intact) and backward\n",
    "h_prev = torch.zeros(batch_size, hidden_size)\n",
    "hiddens = torch.zeros(batch_size, seq_len, hidden_size)\n",
    "for t in range(seq_len):\n",
    "    x_t = inputs[:, t, :]\n",
    "    h_prev = torch.tanh(x_t @ U + h_prev @ W + b)\n",
    "    hiddens[:, t, :] = h_prev\n",
    "\n",
    "h_last = hiddens[:, -1, :]\n",
    "logits = h_last @ V + c\n",
    "loss = criterion(logits, random_labels)\n",
    "loss.backward()\n",
    "\n",
    "for name, p in zip([\"U\",\"W\",\"b\",\"V\",\"c\"], params):\n",
    "    print(f\"{name}.grad norm: {p.grad.norm().item():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bEkHFzOovBx1"
   },
   "source": [
    "(6) Finally, let assume that the learning rate $\\eta = 0.1$, you need to write the code to **manually** update the new model parameters using the SGD manner.\n",
    "\n",
    "<div style=\"text-align: right\"><font color=\"red\">[2 marks]</font></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "2zFSfys8wMqs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.7968389987945557\n",
      "-0.8018071055412292\n"
     ]
    }
   ],
   "source": [
    "#Insert your code here\n",
    "lr = 0.1\n",
    "\n",
    "#before\n",
    "print(params[0][0, 0].item())\n",
    "\n",
    "with torch.no_grad():\n",
    "    for p in params:\n",
    "        p -= lr * p.grad\n",
    "\n",
    "# Check the same parameter after update\n",
    "print(params[0][0, 0].item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rAVPM0BnTdd4"
   },
   "source": [
    "## Section 2: Deep Learning for Sequential Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FAgUSME4TsCP"
   },
   "source": [
    "### <font color=\"#0b486b\">Set random seeds</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "00nhh4IRUcGX"
   },
   "source": [
    "We start with importing PyTorch and NumPy and setting random seeds for PyTorch and NumPy. You can use any seeds you prefer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "O7XWUry0JXCc"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import random\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from transformers import BertTokenizer\n",
    "import os\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "6ZoWqunmUY7L"
   },
   "outputs": [],
   "source": [
    "def seed_all(seed=1029):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "seed_all(seed=1234)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6VU1jS6SUl8q"
   },
   "source": [
    "## <font color=\"#0b486b\">Download and preprocess the data</font>\n",
    "\n",
    "<div style=\"text-align: right\"><font color=\"red; font-weight:bold\"><span></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wQEzWmZjUulL"
   },
   "source": [
    "The dataset we use for this assignment is a question classification dataset for which the training set consists of $5,500$ questions belonging to 6 coarse question categories including:\n",
    "- abbreviation (ABBR),\n",
    "- entity (ENTY),\n",
    "- description (DESC),\n",
    "- human (HUM),\n",
    "- location (LOC) and\n",
    "- numeric (NUM).\n",
    "\n",
    "In this assignment, we will utilize a subset of this dataset, containing $2,000$ questions for training and validation. We will use 80% of those 2000 questions for trainning and the rest for validation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zOd49RTpUxxj"
   },
   "source": [
    "Preprocessing data is a crucial initial step in any machine learning or deep learning project. The *TextDataManager* class simplifies the process by providing functionalities to download and preprocess data specifically designed for the subsequent questions in this assignment. It is highly recommended to gain a comprehensive understanding of the class's functionality by **carefully reading** the content provided in the *TextDataManager* class before proceeding to answer the questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "_C2fuJNzUhha"
   },
   "outputs": [],
   "source": [
    "class DataManager:\n",
    "    \"\"\"\n",
    "    This class manages and preprocesses a simple text dataset for a sentence classification task.\n",
    "\n",
    "    Attributes:\n",
    "        verbose (bool): Controls verbosity for printing information during data processing.\n",
    "        max_sentence_len (int): The maximum length of a sentence in the dataset.\n",
    "        str_questions (list): A list to store the string representations of the questions in the dataset.\n",
    "        str_labels (list): A list to store the string representations of the labels in the dataset.\n",
    "        numeral_labels (list): A list to store the numerical representations of the labels in the dataset.\n",
    "        numeral_data (list): A list to store the numerical representations of the questions in the dataset.\n",
    "        random_state (int): Seed value for random number generation to ensure reproducibility.\n",
    "            Set this value to a specific integer to reproduce the same random sequence every time. Defaults to 6789.\n",
    "        random (np.random.RandomState): Random number generator object initialized with the given random_state.\n",
    "            It is used for various random operations in the class.\n",
    "\n",
    "    Methods:\n",
    "        maybe_download(dir_name, file_name, url, verbose=True):\n",
    "            Downloads a file from a given URL if it does not exist in the specified directory.\n",
    "            The directory and file are created if they do not exist.\n",
    "\n",
    "        read_data(dir_name, file_names):\n",
    "            Reads data from files in a directory, preprocesses it, and computes the maximum sentence length.\n",
    "            Each file is expected to contain rows in the format \"<label>:<question>\".\n",
    "            The labels and questions are stored as string representations.\n",
    "\n",
    "        manipulate_data():\n",
    "            Performs data manipulation by tokenizing, numericalizing, and padding the text data.\n",
    "            The questions are tokenized and converted into numerical sequences using a tokenizer.\n",
    "            The sequences are padded or truncated to the maximum sequence length.\n",
    "\n",
    "        train_valid_test_split(train_ratio=0.9):\n",
    "            Splits the data into training, validation, and test sets based on a given ratio.\n",
    "            The data is randomly shuffled, and the specified ratio is used to determine the size of the training set.\n",
    "            The string questions, numerical data, and numerical labels are split accordingly.\n",
    "            TensorFlow `Dataset` objects are created for the training and validation sets.\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, verbose=True, random_state=6789):\n",
    "        self.verbose = verbose\n",
    "        self.max_sentence_len = 0\n",
    "        self.str_questions = list()\n",
    "        self.str_labels = list()\n",
    "        self.numeral_labels = list()\n",
    "        self.maxlen = None\n",
    "        self.numeral_data = list()\n",
    "        self.random_state = random_state\n",
    "        self.random = np.random.RandomState(random_state)\n",
    "\n",
    "    @staticmethod\n",
    "    def maybe_download(dir_name, file_name, url, verbose=True):\n",
    "        if not os.path.exists(dir_name):\n",
    "            os.mkdir(dir_name)\n",
    "        if not os.path.exists(os.path.join(dir_name, file_name)):\n",
    "            urlretrieve(url + file_name, os.path.join(dir_name, file_name))\n",
    "        if verbose:\n",
    "            print(\"Downloaded successfully {}\".format(file_name))\n",
    "\n",
    "    def read_data(self, dir_name, file_names):\n",
    "        self.str_questions = list()\n",
    "        self.str_labels = list()\n",
    "        for file_name in file_names:\n",
    "            file_path= os.path.join(dir_name, file_name)\n",
    "            with open(file_path, \"r\", encoding=\"latin-1\") as f:\n",
    "                for row in f:\n",
    "                    row_str = row.split(\":\")\n",
    "                    label, question = row_str[0], row_str[1]\n",
    "                    question = question.lower()\n",
    "                    self.str_labels.append(label)\n",
    "                    self.str_questions.append(question[0:-1])\n",
    "                    if self.max_sentence_len < len(self.str_questions[-1]):\n",
    "                        self.max_sentence_len = len(self.str_questions[-1])\n",
    "\n",
    "        # turns labels into numbers\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        le.fit(self.str_labels)\n",
    "        self.numeral_labels = np.array(le.transform(self.str_labels))\n",
    "        self.str_classes = le.classes_\n",
    "        self.num_classes = len(self.str_classes)\n",
    "        if self.verbose:\n",
    "            print(\"\\nSample questions and corresponding labels... \\n\")\n",
    "            print(self.str_questions[0:5])\n",
    "            print(self.str_labels[0:5])\n",
    "\n",
    "    def manipulate_data(self):\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "        vocab = self.tokenizer.get_vocab()\n",
    "        self.word2idx = {w: i for i, w in enumerate(vocab)}\n",
    "        self.idx2word = {i:w for w,i in self.word2idx.items()}\n",
    "        self.vocab_size = len(self.word2idx)\n",
    "\n",
    "        token_ids = []\n",
    "        num_seqs = []\n",
    "        for text in self.str_questions:  # iterate over the list of text\n",
    "          text_seqs = self.tokenizer.tokenize(str(text))  # tokenize each text individually\n",
    "          # Convert tokens to IDs\n",
    "          token_ids = self.tokenizer.convert_tokens_to_ids(text_seqs)\n",
    "          # Convert token IDs to a tensor of indices using your word2idx mapping\n",
    "          seq_tensor = torch.LongTensor(token_ids)\n",
    "          num_seqs.append(seq_tensor)  # append the tensor for each sequence\n",
    "\n",
    "        # Pad the sequences and create a tensor\n",
    "        if num_seqs:\n",
    "          self.numeral_data = pad_sequence(num_seqs, batch_first=True)  # Pads to max length of the sequences\n",
    "          self.num_sentences, self.maxlen = self.numeral_data.shape\n",
    "\n",
    "    def train_valid_test_split(self, train_ratio=0.8, test_ratio = 0.1):\n",
    "        train_size = int(self.num_sentences*train_ratio) +1\n",
    "        test_size = int(self.num_sentences*test_ratio) +1\n",
    "        valid_size = self.num_sentences - (train_size + test_size)\n",
    "        data_indices = list(range(self.num_sentences))\n",
    "        random.shuffle(data_indices)\n",
    "        self.train_str_questions = [self.str_questions[i] for i in data_indices[:train_size]]\n",
    "        self.train_numeral_labels = self.numeral_labels[data_indices[:train_size]]\n",
    "        train_set_data = self.numeral_data[data_indices[:train_size]]\n",
    "        train_set_labels = self.numeral_labels[data_indices[:train_size]]\n",
    "        train_set_labels = torch.from_numpy(train_set_labels)\n",
    "        train_set = torch.utils.data.TensorDataset(train_set_data, train_set_labels)\n",
    "        self.test_str_questions = [self.str_questions[i] for i in data_indices[-test_size:]]\n",
    "        self.test_numeral_labels = self.numeral_labels[data_indices[-test_size:]]\n",
    "        test_set_data = self.numeral_data[data_indices[-test_size:]]\n",
    "        test_set_labels = self.numeral_labels[data_indices[-test_size:]]\n",
    "        test_set_labels = torch.from_numpy(test_set_labels)\n",
    "        test_set = torch.utils.data.TensorDataset(test_set_data, test_set_labels)\n",
    "        self.valid_str_questions = [self.str_questions[i] for i in data_indices[train_size:-test_size]]\n",
    "        self.valid_numeral_labels = self.numeral_labels[data_indices[train_size:-test_size]]\n",
    "        valid_set_data = self.numeral_data[data_indices[train_size:-test_size]]\n",
    "        valid_set_labels = self.numeral_labels[data_indices[train_size:-test_size]]\n",
    "        valid_set_labels = torch.from_numpy(valid_set_labels)\n",
    "        valid_set = torch.utils.data.TensorDataset(valid_set_data, valid_set_labels)\n",
    "        self.train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "        self.test_loader = DataLoader(test_set, batch_size=64, shuffle=False)\n",
    "        self.valid_loader = DataLoader(valid_set, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3npdESj6Vb_t",
    "outputId": "7822da78-eb83-4989-c737-a75aef97d134"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Downloaded successfully train_2000.label\n",
      "\n",
      "Sample questions and corresponding labels... \n",
      "\n",
      "['manner how did serfdom develop in and then leave russia ?', 'cremat what films featured the character popeye doyle ?', \"manner how can i find a list of celebrities ' real names ?\", 'animal what fowl grabs the spotlight after the chinese year of the monkey ?', 'exp what is the full form of .com ?']\n",
      "['DESC', 'ENTY', 'DESC', 'ENTY', 'ABBR']\n"
     ]
    }
   ],
   "source": [
    "print('Loading data...')\n",
    "DataManager.maybe_download(\"data\", \"train_2000.label\", \"http://cogcomp.org/Data/QA/QC/\")\n",
    "\n",
    "dm = DataManager()\n",
    "dm.read_data(\"data/\", [\"train_2000.label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 310,
     "referenced_widgets": [
      "2b5d8a6cfdfe4b1e95449279f82761c3",
      "de01c2173d0e440685eb1ac9b884988f",
      "4e32263423444dc8901f4d23cc2b330d",
      "91e59f5a40fc40d983e35386990324d6",
      "37d50405bf0b4e4680f81c082b2e8840",
      "4943de4fa70944cf89e7ca5adfb8273d",
      "7e8d325cf40240fa9b02ede10425ef4e",
      "4761b8cd787c4e63bc46796aca463292",
      "260d4df916764a05a3ada3064296c23b",
      "0db82c9c23d2441d8953e0a47ca01a6b",
      "c34b8a2216574fedbab6a7a596cbc626",
      "f10cf00b28084470ba4dfba1d8a5996d",
      "a72f9d0d378e4c2e9c465d236210b28b",
      "c4f76fdc51b442788f80ab75d79fd969",
      "b9c39c7dff8d4a74a1b7c4f2a686f8c1",
      "c4ae7881130f4e199782e7cc5eb8d8a0",
      "7c9283ea1d5349829123ef15d32aee58",
      "240ea606f4c2434b88965d5a222e4051",
      "2ee0fb07a3974a9cb150fb3accf13c5d",
      "50486104aed747bebdf05efb8a039b7b",
      "37b55f5eea464a77ae5744b86fd294f1",
      "1d3acfbcd78b41e4bd648089e271ed9d",
      "74ac7c2dfc1f4868932a4542b4488604",
      "41cfa051ce84475fbd822b1b1e9ceda4",
      "1f4e711b1e5c480db1261ba94de9efba",
      "a50640383277495291b29f090f4e6b42",
      "8da1e203b84d49f08564f1f2f5fff662",
      "226ea735f94f4ec1bc3e84c98230c170",
      "bf6ee7481825400288abd9abc8585e91",
      "2770be23025f4d5c990b581a171b3160",
      "d17c96976faa4bf2b1b6eac10bb7fc61",
      "dd081a5b24b0459fbb0499041ca6078e",
      "61e6a3b02d574088afee41257a6e72f0",
      "7ae77f5e5f5e4906bc793f3e40edf881",
      "87e8f90800084eab9da3d5abbb8731b8",
      "5aa6842e49594cb98382d9c1639e6f4e",
      "45665a851e7f425bbaf07666f397d97d",
      "dad255bf2c19468ebb366d512e791192",
      "26020e573f5f4503b9030a046ba25d98",
      "502c1c79d2f348eb868194ec493cd110",
      "86f6064c5e174041a5088431df791154",
      "4ab2a6c9c7da44a981cd26448e125c19",
      "df14ee10fe6c44a7a7cd6ba44ce50704",
      "5ab79ed067c0474f95f89938f97a92cf"
     ]
    },
    "id": "EgrYZPmyVj60",
    "outputId": "3609ecf0-4154-4aa4-954d-aee636096ade"
   },
   "outputs": [],
   "source": [
    "dm.manipulate_data()\n",
    "dm.train_valid_test_split(train_ratio=0.8, test_ratio = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bH-U0sUMVnW-",
    "outputId": "6b3e6b8f-4064-4c9f-d4c0-69d59c109ae0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 36]) torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "for x, y in dm.train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "frFf7-ehVvNM"
   },
   "source": [
    "## <font color=\"#0b486b\">Part 1: Using Word2Vect to transform texts to vectors </font>\n",
    "\n",
    "<div style=\"text-align: right\"><font color=\"red; font-weight:bold\">[Total marks for this part: 10 marks]<span></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "KZFrETlMVq7P"
   },
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4JH-f1BJY9bw"
   },
   "source": [
    "#### <font color=\"red\">**Question 1.1**</font>\n",
    "**Write code to download the pretrained model *glove-wiki-gigaword-100*. Note that this model transforms a word in its dictionary to a $100$ dimensional vector.**\n",
    "\n",
    "**Write code for the function *get_word_vector(word, model)* used to transform a word to a vector using the pretrained Word2Vect model *model*. Note that for a word not in the vocabulary of our *word2vect*, you need to return a vector $0$ with 100 dimensions.**\n",
    "\n",
    "<div style=\"text-align: right\"><font color=\"red\">[2 marks]</font></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b76lh_hZVyac",
    "outputId": "0cd87611-e3db-4e51-c336-9e1b084317f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 128.1/128.1MB downloaded\n"
     ]
    }
   ],
   "source": [
    "word2vect = api.load(\"glove-wiki-gigaword-100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "GpbibKfdZB-S"
   },
   "outputs": [],
   "source": [
    "def get_word_vector(word, model):\n",
    "    try:\n",
    "        vector = model.get_vector(word)\n",
    "    except:\n",
    "        vector = np.zeros(model.vector_size, dtype=np.float32)\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8TjRdyTg2_dN"
   },
   "source": [
    "#### <font color=\"red\">**Question 1.2**</font>\n",
    "\n",
    "**Write the code for the function `get_sentence_vector(sentence, important_score=None, model= None)`. Note that this function will transform a sentence to a 100-dimensional vector using the pretrained model *model*. In addition, the list *important_score* which has the same length as the *sentence* specifies the important scores of the words in the sentence. In your code, you first need to apply *softmax* function over *important_score* to obtain the important weight *important_weight* which forms a probability over the words of the sentence. Furthermore, the final vector of the sentence will be weighted sum of the individual vectors for words and the weights in *important_weight*.**\n",
    "- $important\\_weight = softmax(important\\_score)$.\n",
    "- $final\\_vector= important\\_weight[1]\\times v[1] + important\\_weight[2]\\times v[2] + ...+ important\\_weight[T]\\times v[T]$ where $T$ is the length of the sentence and $v[i]$ is the vector representation of the $i-th$  word in this sentence.\n",
    "\n",
    "**Note that if `important_score=None` is set by default, your function should return the average of all representation vectors corresponding to set `important_score=[1,1,...,1]`.**\n",
    "\n",
    "<div style=\"text-align: right\"><font color=\"red\">[2 marks]</font></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "MaPs4Hqa2_30"
   },
   "outputs": [],
   "source": [
    "\n",
    "def _softmax(x):\n",
    "    x = np.asarray(x, dtype=np.float32)\n",
    "    x -= x.max()                      # numerical stability\n",
    "    ex = np.exp(x)\n",
    "    return ex / (ex.sum() + 1e-12)\n",
    "\n",
    "#If important_score is None, use a uniform average. If provided, softmax the scores and take a weighted sum.\n",
    "def get_sentence_vector(sentence, important_score=None, model=None):\n",
    "    \"\"\"important_score: list/array (len = #tokens). If None -> uniform average.\n",
    "    model: pretrained KeyedVectors (e.g., GloVe).\n",
    "    \"\"\"\n",
    "    assert model is not None, \"Please pass the pretrained model\"\n",
    "\n",
    "    # very simple tokenization (assignment usually expects this)\n",
    "    tokens = sentence.strip().lower().split()\n",
    "    if len(tokens) == 0:\n",
    "        return np.zeros(model.vector_size, dtype=np.float32)\n",
    "\n",
    "    # collect word vectors (OOV -> zeros)\n",
    "    vecs = np.stack([get_word_vector(w, model) for w in tokens], axis=0)  # [T, D]\n",
    "\n",
    "    if important_score is None:\n",
    "        # uniform average\n",
    "        feature_vector = vecs.mean(axis=0)\n",
    "    else:\n",
    "        # softmax -> weights sum to 1\n",
    "        weights = _softmax(important_score)           # [T]\n",
    "        feature_vector = (weights[:, None] * vecs).sum(axis=0)\n",
    "\n",
    "    return feature_vector.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tu63GJ2c3IgZ"
   },
   "source": [
    "#### <font color=\"red\">**Question 1.3**</font>\n",
    "\n",
    "**Write code to transform questions in *dm.train_str_questions* and *dm.valid_str_questions* to feature vectors. Note that after running the following cells, you must have $X\\_train$ and $X\\_valid$ which are two NumPy arrays of the feature vectors and $y\\_train$ and $y\\_valid$ which are two arrays of numeric labels (Hint: *dm.train_numeral_labels* and *dm.valid_numeral_labels*). You can add more lines to the following cells if necessary. In addition, you should decide the *important_score* by yourself. For example, the 1st score is 1, the 2nd score is decayed by 0.9, the 3rd is decayed by 0.9, and so on.**\n",
    "\n",
    "<div style=\"text-align: right\"><font color=\"red\">[2 marks]</font></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def decayed_importance(n_tokens, gamma=0.9):\n",
    "    return np.power(gamma, np.arange(n_tokens, dtype=np.float32)) # [1, gamma, gamma^2, ...]  \u2192 any length T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5SCsWIdZ3I4S",
    "outputId": "4691df38-1e88-47cf-c392-378a0086dfc5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transform training set to feature vectors...\n"
     ]
    }
   ],
   "source": [
    "print(\"Transform training set to feature vectors...\")\n",
    "X_train = []\n",
    "y_train = dm.train_numeral_labels\n",
    "for s in dm.train_str_questions:\n",
    "    T = max(1, len(s.strip().split()))\n",
    "    imp = decayed_importance(T, gamma=0.9)\n",
    "    x = get_sentence_vector(s, important_score=imp, model=word2vect)\n",
    "    X_train.append(x)\n",
    "X_train = np.stack(X_train, axis=0).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2odznptZ3Nf_",
    "outputId": "d007af2d-bbef-436a-ee62-7940a83fdf5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transform validation set to feature vectors...\n"
     ]
    }
   ],
   "source": [
    "print(\"Transform validation set to feature vectors...\")\n",
    "X_valid = []\n",
    "y_valid = dm.valid_numeral_labels\n",
    "for s in dm.valid_str_questions:\n",
    "    T = max(1, len(s.strip().split()))\n",
    "    imp = decayed_importance(T, gamma=0.9)\n",
    "    x = get_sentence_vector(s, important_score=imp, model=word2vect)\n",
    "    X_valid.append(x)\n",
    "X_valid = np.stack(X_valid, axis=0).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes \u2192 X_train: (1601, 100)  y_train: (1601,) | X_valid: (198, 100)  y_valid: (198,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shapes \u2192 X_train:\", X_train.shape, \" y_train:\", y_train.shape,\n",
    "      \"| X_valid:\", X_valid.shape, \" y_valid:\", y_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gOp_gy3d3Reh"
   },
   "source": [
    "#### <font color=\"red\">**Question 1.4**</font>\n",
    "\n",
    "**It is now to use *MinMaxScaler(feature_range=(-1,1))* in scikit-learn to scale both training and validation sets to the range $(-1,1)$.**\n",
    "\n",
    "<div style=\"text-align: right\"><font color=\"red\">[2 marks]</font></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eT47Q13c3VJV",
    "outputId": "9320ccc2-263b-4fb6-ec6e-19cc52a0a800"
   },
   "outputs": [],
   "source": [
    "#Insert your code\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "X_train_scaled = scaler.fit_transform(X_train)   # fit on TRAIN only\n",
    "X_valid_scaled = scaler.transform(X_valid)       # transform VALID with same scaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NcvKQyHO3ZJx"
   },
   "source": [
    "#### <font color=\"red\">**Question 1.5**</font>\n",
    "**Train a Logistic Regression model on the training set and then evaluate on the validation set.** You can use any classification metrics in `sklearn` for evaluation.\n",
    "<div style=\"text-align: right\"><font color=\"red\">[2 marks]</font></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "IQYE_rz-3b25"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiseok/miniforge3/envs/nlp/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\u25b8\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\u25be\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000, multi_class=&#x27;multinomial&#x27;, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('penalty',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">penalty&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;l2&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('dual',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">dual&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tol&nbsp;</td>\n",
       "            <td class=\"value\">0.0001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('C',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">C&nbsp;</td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('fit_intercept',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">fit_intercept&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('intercept_scaling',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">intercept_scaling&nbsp;</td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">class_weight&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('solver',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">solver&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;lbfgs&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_iter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_iter&nbsp;</td>\n",
       "            <td class=\"value\">1000</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('multi_class',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">multi_class&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;multinomial&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">warm_start&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('l1_ratio',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">l1_ratio&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000, multi_class='multinomial', random_state=0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "#Insert your code\n",
    "# multinomial logistic regression (softmax) for 6 classes\n",
    "logreg = LogisticRegression(\n",
    "    multi_class=\"multinomial\",\n",
    "    solver=\"lbfgs\",\n",
    "    max_iter=1000,\n",
    "    random_state=0)\n",
    "logreg.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "ucJWNHMO3gXF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.9040\n",
      "F1 (macro): 0.8598 | F1 (weighted): 0.9031\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ABBR       1.00      0.50      0.67         2\n",
      "        DESC       0.91      0.86      0.89        36\n",
      "        ENTY       0.89      0.87      0.88        54\n",
      "         HUM       0.96      1.00      0.98        52\n",
      "         LOC       0.84      0.90      0.87        29\n",
      "         NUM       0.88      0.88      0.88        25\n",
      "\n",
      "    accuracy                           0.90       198\n",
      "   macro avg       0.91      0.83      0.86       198\n",
      "weighted avg       0.90      0.90      0.90       198\n",
      "\n",
      "Confusion matrix:\n",
      " [[ 1  1  0  0  0  0]\n",
      " [ 0 31  2  1  1  1]\n",
      " [ 0  2 47  1  2  2]\n",
      " [ 0  0  0 52  0  0]\n",
      " [ 0  0  3  0 26  0]\n",
      " [ 0  0  1  0  2 22]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "#Insert your code\n",
    "# evaluating validation set \n",
    "y_pred = logreg.predict(X_valid_scaled)\n",
    "\n",
    "val_acc   = metrics.accuracy_score(y_valid, y_pred)\n",
    "f1_macro  = metrics.f1_score(y_valid, y_pred, average=\"macro\")\n",
    "f1_weight = metrics.f1_score(y_valid, y_pred, average=\"weighted\")\n",
    "\n",
    "print(f\"Validation accuracy: {val_acc:.4f}\")\n",
    "print(f\"F1 (macro): {f1_macro:.4f} | F1 (weighted): {f1_weight:.4f}\")\n",
    "\n",
    "# per-class report\n",
    "labels = np.arange(dm.num_classes)\n",
    "print(metrics.classification_report(\n",
    "    y_valid, y_pred,\n",
    "    labels=labels,\n",
    "    target_names=list(dm.str_classes),\n",
    "    zero_division=0\n",
    "))\n",
    "\n",
    "# confusion matrix (rows = true, cols = predicted)\n",
    "print(\"Confusion matrix:\\n\", metrics.confusion_matrix(y_valid, y_pred, labels=labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NZs9Y0rl7gBH"
   },
   "source": [
    "We now declare the `BaseTrainer` class, which will be used later to train the subsequent deep learning models for text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "yXlNQvGn7OEb"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class BaseTrainer:\n",
    "    def __init__(self, model, criterion, optimizer, train_loader, val_loader):\n",
    "        self.model = model\n",
    "        self.criterion = criterion  #the loss function\n",
    "        self.optimizer = optimizer  #the optimizer\n",
    "        self.train_loader = train_loader  #the train loader\n",
    "        self.val_loader = val_loader  #the valid loader\n",
    "\n",
    "    #the function to train the model in many epochs\n",
    "    def fit(self, num_epochs):\n",
    "        self.num_batches = len(self.train_loader)\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            print(f'Epoch {epoch + 1}/{num_epochs}')\n",
    "            train_loss, train_accuracy = self.train_one_epoch()\n",
    "            val_loss, val_accuracy = self.validate_one_epoch()\n",
    "            print(\n",
    "                f'{self.num_batches}/{self.num_batches} - train_loss: {train_loss:.4f} - train_accuracy: {train_accuracy*100:.4f}% \\\n",
    "                - val_loss: {val_loss:.4f} - val_accuracy: {val_accuracy*100:.4f}%')\n",
    "\n",
    "    #train in one epoch, return the train_acc, train_loss\n",
    "    def train_one_epoch(self):\n",
    "        self.model.train()\n",
    "        running_loss, correct, total = 0.0, 0, 0\n",
    "        for i, data in enumerate(self.train_loader):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self.model(inputs)\n",
    "            loss = self.criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        train_accuracy = correct / total\n",
    "        train_loss = running_loss / self.num_batches\n",
    "        return train_loss, train_accuracy\n",
    "\n",
    "    #evaluate on a loader and return the loss and accuracy\n",
    "    def evaluate(self, loader):\n",
    "        self.model.eval()\n",
    "        loss, correct, total = 0.0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for data in loader:\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        accuracy = correct / total\n",
    "        loss = loss / len(self.val_loader)\n",
    "        return loss, accuracy\n",
    "\n",
    "    #return the val_acc, val_loss, be called at the end of each epoch\n",
    "    def validate_one_epoch(self):\n",
    "      val_loss, val_accuracy = self.evaluate(self.val_loader)\n",
    "      return val_loss, val_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3GWOQN_S7p4V"
   },
   "source": [
    "## <font color=\"#0b486b\">Part 2: Text CNN for sequence modeling and neural embedding </font>\n",
    "\n",
    "<div style=\"text-align: right\"><font color=\"red; font-weight:bold\">[Total marks for this part: 10 marks]<span></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QJub3Fwm7vC7"
   },
   "source": [
    "**In what follows, you are required to complete the code for Text CNN for sentence classification. The paper of Text CNN can be found at this [link](https://www.aclweb.org/anthology/D14-1181.pdf). Here is the description of the Text CNN that you need to construct.**\n",
    "- There are three attributes (properties or instance variables): *embed_size, state_size, data_manager*.\n",
    "  - `embed_size`: the dimension of the vector space for which the words are embedded to using the embedding matrix.\n",
    "  - `state_size`: the number of filters used in *Conv1D* (reference [here](https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html)).\n",
    "  - `data_manager`: the data manager to store information of the dataset.\n",
    "- The detail of the computational process is as follows:\n",
    "  - Given input $x$, we embed $x$ using the embedding matrix to obtain an $3D$ tensor $[batch\\_size, seq\\_len, embed\\_size]$ as $e$.\n",
    "  - We feed $e$ to three *Conv1D* layers, each of which has $state\\_size$ filters, activation= $relu$, and $kernel\\_size= 3, 5, 7$ respectively to obtain $h1, h2, h3$. Note that each $h1, h2, h3$ is a 3D tensor with the shape $[batch\\_size, state\\_size, output\\_size]$. Moreover, you need to apply *Conv1D* to the $seq\\_len$ dimension.\n",
    "  - We then apply *GlobalMaxPool1D()* (reference [here](https://pytorch.org/docs/stable/generated/torch.nn.functional.max_pool1d.html#torch.nn.functional.max_pool1d)) over $h1, h2, h3$ to obtain 2D tensors stored in $h1, h2, h3$ again.\n",
    "  - We then concatenate three 2D tensors $h1, h2, h3$ to obtain $h$ with the shape $\\left[batch\\_size, 3\\times state\\_size\\right]$. Note that you need to specify the axis to concatenate.\n",
    "  - We finally build up one dense layer $\\left[3\\times state\\_size, num\\_classes\\right]$  on the top of $h$ for classification.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "lEnG-BGJ239k"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#You can modify the code if you want but need to keep the skeleton\n",
    "class TextCNN(torch.nn.Module):\n",
    "    def __init__(self, embed_size= 128, state_size=16, data_manager=None):\n",
    "        super(TextCNN, self).__init__()\n",
    "        self.data_manager = data_manager\n",
    "        self.embed_size = embed_size\n",
    "        self.state_size = state_size\n",
    "        #declare the necessary layers here\n",
    "        self.embed = nn.Embedding(self.data_manager.vocab_size, self.embed_size)\n",
    "        self.conv1d_1 = nn.Conv1d(in_channels=self.embed_size, out_channels=self.state_size,\n",
    "                                  kernel_size=3, padding=1, dilation=1)\n",
    "        self.conv1d_2 = nn.Conv1d(in_channels=self.embed_size, out_channels=self.state_size,\n",
    "                                  kernel_size=5, padding=2, dilation=1)\n",
    "        self.conv1d_3 = nn.Conv1d(in_channels=self.embed_size, out_channels=self.state_size,\n",
    "                                  kernel_size=7, padding=3, dilation=1)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "        self.fc = nn.Linear(state_size*3, self.data_manager.num_classes)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        e = self.embed(x)   # [B, T, E]\n",
    "        #permute x before applying Conv1D\n",
    "        e= e.permute(0,2,1)\n",
    "\n",
    "        #applying Conv1D\n",
    "        # [B, S, L]\n",
    "        h1 = F.relu(self.conv1d_1(e))   \n",
    "        h2 = F.relu(self.conv1d_2(e))   \n",
    "        h3 = F.relu(self.conv1d_3(e))   \n",
    "\n",
    "        #apply GlobalMaxPool\n",
    "        # [B, state_size]\n",
    "        h1 = F.adaptive_max_pool1d(h1, 1).squeeze(-1)   \n",
    "        h2 = F.adaptive_max_pool1d(h2, 1).squeeze(-1)   \n",
    "        h3 = F.adaptive_max_pool1d(h3, 1).squeeze(-1)\n",
    "\n",
    "        h =  torch.cat((h1, h2, h3), dim=1)     # [B, 3*state_size]\n",
    "        h = self.fc(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n-PN6KmIFw6K"
   },
   "source": [
    "We declare `text_cnn` and train on several epochs (e.g., `50 epochs`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IrL5oM82BR3_",
    "outputId": "494f66d3-98b3-4768-8d82-46e32f1134aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "26/26 - train_loss: 1.5139 - train_accuracy: 47.9076%                 - val_loss: 0.4696 - val_accuracy: 76.2626%\n",
      "Epoch 2/50\n",
      "26/26 - train_loss: 0.7301 - train_accuracy: 84.6346%                 - val_loss: 0.1886 - val_accuracy: 85.3535%\n",
      "Epoch 3/50\n",
      "26/26 - train_loss: 0.3764 - train_accuracy: 91.4428%                 - val_loss: 0.0993 - val_accuracy: 93.9394%\n",
      "Epoch 4/50\n",
      "26/26 - train_loss: 0.2228 - train_accuracy: 95.6902%                 - val_loss: 0.0532 - val_accuracy: 94.4444%\n",
      "Epoch 5/50\n",
      "26/26 - train_loss: 0.1394 - train_accuracy: 97.8139%                 - val_loss: 0.0364 - val_accuracy: 94.4444%\n",
      "Epoch 6/50\n",
      "26/26 - train_loss: 0.0919 - train_accuracy: 99.3754%                 - val_loss: 0.0239 - val_accuracy: 95.4545%\n",
      "Epoch 7/50\n",
      "26/26 - train_loss: 0.0692 - train_accuracy: 99.6877%                 - val_loss: 0.0202 - val_accuracy: 94.9495%\n",
      "Epoch 8/50\n",
      "26/26 - train_loss: 0.0528 - train_accuracy: 99.5003%                 - val_loss: 0.0134 - val_accuracy: 95.4545%\n",
      "Epoch 9/50\n",
      "26/26 - train_loss: 0.0394 - train_accuracy: 99.8751%                 - val_loss: 0.0118 - val_accuracy: 95.9596%\n",
      "Epoch 10/50\n",
      "26/26 - train_loss: 0.0280 - train_accuracy: 99.9375%                 - val_loss: 0.0091 - val_accuracy: 95.9596%\n",
      "Epoch 11/50\n",
      "26/26 - train_loss: 0.0224 - train_accuracy: 100.0000%                 - val_loss: 0.0078 - val_accuracy: 95.9596%\n",
      "Epoch 12/50\n",
      "26/26 - train_loss: 0.0180 - train_accuracy: 100.0000%                 - val_loss: 0.0069 - val_accuracy: 95.9596%\n",
      "Epoch 13/50\n",
      "26/26 - train_loss: 0.0145 - train_accuracy: 100.0000%                 - val_loss: 0.0059 - val_accuracy: 95.9596%\n",
      "Epoch 14/50\n",
      "26/26 - train_loss: 0.0122 - train_accuracy: 100.0000%                 - val_loss: 0.0048 - val_accuracy: 95.9596%\n",
      "Epoch 15/50\n",
      "26/26 - train_loss: 0.0112 - train_accuracy: 100.0000%                 - val_loss: 0.0044 - val_accuracy: 95.9596%\n",
      "Epoch 16/50\n",
      "26/26 - train_loss: 0.0094 - train_accuracy: 100.0000%                 - val_loss: 0.0040 - val_accuracy: 95.9596%\n",
      "Epoch 17/50\n",
      "26/26 - train_loss: 0.0078 - train_accuracy: 100.0000%                 - val_loss: 0.0036 - val_accuracy: 96.4646%\n",
      "Epoch 18/50\n",
      "26/26 - train_loss: 0.0069 - train_accuracy: 100.0000%                 - val_loss: 0.0033 - val_accuracy: 96.4646%\n",
      "Epoch 19/50\n",
      "26/26 - train_loss: 0.0060 - train_accuracy: 100.0000%                 - val_loss: 0.0029 - val_accuracy: 96.4646%\n",
      "Epoch 20/50\n",
      "26/26 - train_loss: 0.0053 - train_accuracy: 100.0000%                 - val_loss: 0.0027 - val_accuracy: 96.4646%\n",
      "Epoch 21/50\n",
      "26/26 - train_loss: 0.0048 - train_accuracy: 100.0000%                 - val_loss: 0.0024 - val_accuracy: 96.4646%\n",
      "Epoch 22/50\n",
      "26/26 - train_loss: 0.0044 - train_accuracy: 100.0000%                 - val_loss: 0.0023 - val_accuracy: 96.4646%\n",
      "Epoch 23/50\n",
      "26/26 - train_loss: 0.0039 - train_accuracy: 100.0000%                 - val_loss: 0.0021 - val_accuracy: 96.4646%\n",
      "Epoch 24/50\n",
      "26/26 - train_loss: 0.0035 - train_accuracy: 100.0000%                 - val_loss: 0.0019 - val_accuracy: 96.4646%\n",
      "Epoch 25/50\n",
      "26/26 - train_loss: 0.0032 - train_accuracy: 100.0000%                 - val_loss: 0.0018 - val_accuracy: 96.4646%\n",
      "Epoch 26/50\n",
      "26/26 - train_loss: 0.0037 - train_accuracy: 100.0000%                 - val_loss: 0.0017 - val_accuracy: 96.4646%\n",
      "Epoch 27/50\n",
      "26/26 - train_loss: 0.0031 - train_accuracy: 100.0000%                 - val_loss: 0.0017 - val_accuracy: 96.4646%\n",
      "Epoch 28/50\n",
      "26/26 - train_loss: 0.0026 - train_accuracy: 100.0000%                 - val_loss: 0.0016 - val_accuracy: 96.4646%\n",
      "Epoch 29/50\n",
      "26/26 - train_loss: 0.0024 - train_accuracy: 100.0000%                 - val_loss: 0.0015 - val_accuracy: 96.4646%\n",
      "Epoch 30/50\n",
      "26/26 - train_loss: 0.0022 - train_accuracy: 100.0000%                 - val_loss: 0.0014 - val_accuracy: 96.4646%\n",
      "Epoch 31/50\n",
      "26/26 - train_loss: 0.0020 - train_accuracy: 100.0000%                 - val_loss: 0.0013 - val_accuracy: 96.4646%\n",
      "Epoch 32/50\n",
      "26/26 - train_loss: 0.0019 - train_accuracy: 100.0000%                 - val_loss: 0.0013 - val_accuracy: 96.4646%\n",
      "Epoch 33/50\n",
      "26/26 - train_loss: 0.0018 - train_accuracy: 100.0000%                 - val_loss: 0.0012 - val_accuracy: 96.4646%\n",
      "Epoch 34/50\n",
      "26/26 - train_loss: 0.0018 - train_accuracy: 100.0000%                 - val_loss: 0.0011 - val_accuracy: 96.4646%\n",
      "Epoch 35/50\n",
      "26/26 - train_loss: 0.0016 - train_accuracy: 100.0000%                 - val_loss: 0.0011 - val_accuracy: 96.4646%\n",
      "Epoch 36/50\n",
      "26/26 - train_loss: 0.0015 - train_accuracy: 100.0000%                 - val_loss: 0.0011 - val_accuracy: 96.4646%\n",
      "Epoch 37/50\n",
      "26/26 - train_loss: 0.0014 - train_accuracy: 100.0000%                 - val_loss: 0.0010 - val_accuracy: 96.4646%\n",
      "Epoch 38/50\n",
      "26/26 - train_loss: 0.0013 - train_accuracy: 100.0000%                 - val_loss: 0.0010 - val_accuracy: 96.4646%\n",
      "Epoch 39/50\n",
      "26/26 - train_loss: 0.0012 - train_accuracy: 100.0000%                 - val_loss: 0.0009 - val_accuracy: 96.4646%\n",
      "Epoch 40/50\n",
      "26/26 - train_loss: 0.0012 - train_accuracy: 100.0000%                 - val_loss: 0.0009 - val_accuracy: 96.4646%\n",
      "Epoch 41/50\n",
      "26/26 - train_loss: 0.0011 - train_accuracy: 100.0000%                 - val_loss: 0.0009 - val_accuracy: 96.4646%\n",
      "Epoch 42/50\n",
      "26/26 - train_loss: 0.0010 - train_accuracy: 100.0000%                 - val_loss: 0.0008 - val_accuracy: 96.4646%\n",
      "Epoch 43/50\n",
      "26/26 - train_loss: 0.0011 - train_accuracy: 100.0000%                 - val_loss: 0.0008 - val_accuracy: 96.4646%\n",
      "Epoch 44/50\n",
      "26/26 - train_loss: 0.0009 - train_accuracy: 100.0000%                 - val_loss: 0.0008 - val_accuracy: 96.4646%\n",
      "Epoch 45/50\n",
      "26/26 - train_loss: 0.0009 - train_accuracy: 100.0000%                 - val_loss: 0.0008 - val_accuracy: 96.4646%\n",
      "Epoch 46/50\n",
      "26/26 - train_loss: 0.0009 - train_accuracy: 100.0000%                 - val_loss: 0.0007 - val_accuracy: 96.4646%\n",
      "Epoch 47/50\n",
      "26/26 - train_loss: 0.0008 - train_accuracy: 100.0000%                 - val_loss: 0.0007 - val_accuracy: 96.4646%\n",
      "Epoch 48/50\n",
      "26/26 - train_loss: 0.0008 - train_accuracy: 100.0000%                 - val_loss: 0.0007 - val_accuracy: 96.4646%\n",
      "Epoch 49/50\n",
      "26/26 - train_loss: 0.0007 - train_accuracy: 100.0000%                 - val_loss: 0.0007 - val_accuracy: 96.4646%\n",
      "Epoch 50/50\n",
      "26/26 - train_loss: 0.0007 - train_accuracy: 100.0000%                 - val_loss: 0.0007 - val_accuracy: 96.4646%\n"
     ]
    }
   ],
   "source": [
    "text_cnn = TextCNN(data_manager=dm).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(text_cnn.parameters(), lr=0.001)\n",
    "trainer = BaseTrainer(model=text_cnn, criterion=criterion, optimizer=optimizer, train_loader=dm.train_loader, val_loader=dm.valid_loader)\n",
    "trainer.fit(num_epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yrjO5iT6F_Li"
   },
   "source": [
    "We evaluate the trained model on the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CnHiWCl7BtJC",
    "outputId": "ba7b7eba-d589-4b2e-fd10-57b7127ca61f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 0.1381 - test_accuracy: 97.0149%\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = trainer.evaluate(dm.test_loader)\n",
    "print(f'test_loss: {test_loss:.4f} - test_accuracy: {test_acc*100:.4f}%')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}