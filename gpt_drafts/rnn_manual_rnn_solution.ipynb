{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30387c25",
   "metadata": {},
   "source": [
    "# Section 1: Fundamentals in RNNs — Worked Solution\n",
    "*Generated on 2025-11-04 11:52:06*\n",
    "\n",
    "This notebook implements a **manual multi-timestep RNN** in PyTorch and answers all parts (1)–(6)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a223bcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10d02f730>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (0) Import\n",
    "import torch\n",
    "torch.set_printoptions(sci_mode=False, precision=4)\n",
    "torch.manual_seed(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d5d813f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs.shape: torch.Size([8, 4, 5])\n",
      "random_labels: tensor([1, 2, 2, 2, 2, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "# (Given) Declare variables\n",
    "input_size = 5\n",
    "seq_len = 4\n",
    "batch_size = 8\n",
    "hidden_size = 3\n",
    "num_classes = 3\n",
    "\n",
    "# Create random inputs and random labels\n",
    "inputs = torch.randn(batch_size, seq_len, input_size)\n",
    "random_labels = torch.randint(0, num_classes, (batch_size,))\n",
    "print(\"inputs.shape:\", inputs.shape)\n",
    "print(\"random_labels:\", random_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accde829",
   "metadata": {},
   "source": [
    "## (1) Declare model parameters U, W, V, b, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db53f95b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U: torch.Size([5, 3]) W: torch.Size([3, 3]) b: torch.Size([3]) V: torch.Size([3, 3]) c: torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "# U: (input_size, hidden_size)\n",
    "# W: (hidden_size, hidden_size)\n",
    "# b: (hidden_size,)\n",
    "# V: (hidden_size, num_classes)\n",
    "# c: (num_classes,)\n",
    "\n",
    "# Kaiming initialization for weights; zeros for biases\n",
    "U = torch.nn.Parameter(torch.randn(input_size, hidden_size) * (2/hidden_size)**0.5)\n",
    "W = torch.nn.Parameter(torch.randn(hidden_size, hidden_size) * (2/hidden_size)**0.5)\n",
    "b = torch.nn.Parameter(torch.zeros(hidden_size))\n",
    "V = torch.nn.Parameter(torch.randn(hidden_size, num_classes) * (2/hidden_size)**0.5)\n",
    "c = torch.nn.Parameter(torch.zeros(num_classes))\n",
    "\n",
    "params = [U, W, b, V, c]\n",
    "for p in params:\n",
    "    p.requires_grad_(True)\n",
    "\n",
    "print(\"U:\", U.shape, \"W:\", W.shape, \"b:\", b.shape, \"V:\", V.shape, \"c:\", c.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0b25e2",
   "metadata": {},
   "source": [
    "## (2) Compute `hiddens` (batch_size, seq_len, hidden_size) using a simple RNN cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ebd8f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hiddens.shape: torch.Size([8, 4, 3])\n",
      "last hidden sample (first 2 rows):\n",
      " tensor([[ 0.9996, -0.9977, -0.9888],\n",
      "        [-0.9293,  0.9716, -0.8190]], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Initialize hiddens for update\n",
    "hiddens = torch.zeros(batch_size, seq_len, hidden_size)\n",
    "\n",
    "# Manual simple RNN forward: h_t = tanh(x_t @ U + h_{t-1} @ W + b)\n",
    "h_prev = torch.zeros(batch_size, hidden_size)\n",
    "for t in range(seq_len):\n",
    "    x_t = inputs[:, t, :]                               # (batch_size, input_size)\n",
    "    h_t = torch.tanh(x_t @ U + h_prev @ W + b)          # (batch_size, hidden_size)\n",
    "    hiddens[:, t, :] = h_t\n",
    "    h_prev = h_t\n",
    "\n",
    "print(\"hiddens.shape:\", hiddens.shape)\n",
    "print(\"last hidden sample (first 2 rows):\\n\", hiddens[:2, -1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea67658",
   "metadata": {},
   "source": [
    "## (3) Compute logits from the **last** hidden state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b452039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits.shape: torch.Size([8, 3])\n",
      "tensor([[ 1.3990,  0.2307,  0.7709],\n",
      "        [-1.1064,  0.1209,  0.8236],\n",
      "        [-0.6812, -0.2259,  0.7966]], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Take last hidden state: (batch_size, hidden_size)\n",
    "h_last = hiddens[:, -1, :]\n",
    "logits = h_last @ V + c                                  # (batch_size, num_classes)\n",
    "print(\"logits.shape:\", logits.shape)\n",
    "print(logits[:3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52900950",
   "metadata": {},
   "source": [
    "## (4) Cross-entropy loss vs. labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1ae0a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.2063236236572266\n",
      "tensor(1.2063, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "loss = criterion(logits, random_labels)\n",
    "print(\"loss:\", loss.item())\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a43cf70",
   "metadata": {},
   "source": [
    "## (5) Back-propagation to compute gradients w.r.t. parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "713635c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U.grad norm: 0.374913\n",
      "W.grad norm: 0.284781\n",
      "b.grad norm: 0.174993\n",
      "V.grad norm: 0.721826\n",
      "c.grad norm: 0.295514\n"
     ]
    }
   ],
   "source": [
    "# Zero grads (in case this cell is re-run)\n",
    "for p in params:\n",
    "    if p.grad is not None:\n",
    "        p.grad.zero_()\n",
    "\n",
    "# Recompute forward (so graph is intact) and backward\n",
    "h_prev = torch.zeros(batch_size, hidden_size)\n",
    "hiddens = torch.zeros(batch_size, seq_len, hidden_size)\n",
    "for t in range(seq_len):\n",
    "    x_t = inputs[:, t, :]\n",
    "    h_prev = torch.tanh(x_t @ U + h_prev @ W + b)\n",
    "    hiddens[:, t, :] = h_prev\n",
    "\n",
    "h_last = hiddens[:, -1, :]\n",
    "logits = h_last @ V + c\n",
    "loss = criterion(logits, random_labels)\n",
    "loss.backward()\n",
    "\n",
    "for name, p in zip([\"U\",\"W\",\"b\",\"V\",\"c\"], params):\n",
    "    print(f\"{name}.grad norm: {p.grad.norm().item():.6f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0f9dad",
   "metadata": {},
   "source": [
    "## (6) Manual SGD update with learning rate η = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f5df3ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss after one SGD step: 1.1136271953582764\n"
     ]
    }
   ],
   "source": [
    "lr = 0.1\n",
    "with torch.no_grad():\n",
    "    for p in params:\n",
    "        p -= lr * p.grad\n",
    "\n",
    "# Optionally compute loss again after one update\n",
    "# (detach inputs to avoid autograd tracking across steps)\n",
    "h_prev = torch.zeros(batch_size, hidden_size)\n",
    "hiddens = torch.zeros(batch_size, seq_len, hidden_size)\n",
    "for t in range(seq_len):\n",
    "    x_t = inputs[:, t, :]\n",
    "    h_prev = torch.tanh(x_t @ U + h_prev @ W + b)\n",
    "    hiddens[:, t, :] = h_prev\n",
    "\n",
    "new_logits = hiddens[:, -1, :] @ V + c\n",
    "new_loss = criterion(new_logits, random_labels)\n",
    "print(\"loss after one SGD step:\", new_loss.item())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
