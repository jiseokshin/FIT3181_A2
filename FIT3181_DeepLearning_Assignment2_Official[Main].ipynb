{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jiseokshin/FIT3181_A2/blob/main/FIT3181_DeepLearning_Assignment2_Official%5BMain%5D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEHyseHxA8q4"
      },
      "source": [
        "# <font color=\"#0b486b\">  FIT3181: Deep Learning (2025) - Assignment 2 (Section I)</font>\n",
        "***\n",
        "*CE/Lecturer (Clayton):*  **Dr Trung Le** | trunglm@monash.edu <br/>\n",
        "*Lecturer (Clayton):* **A/Prof Zongyuan Ge** | zongyuan.ge@monash.edu <br/>\n",
        "*Lecturer (Malaysia):*  **Dr Arghya Pal** | arghya.pal@monash.edu <br/>\n",
        " <br/>\n",
        "*Head Tutor 3181:*  **Ms Ruda Nie H** |  \\[RudaNie.H@monash.edu \\] <br/>\n",
        "*Head Tutor 5215:*  **Ms Leila Mahmoodi** |  \\[leila.mahmoodi@monash.edu \\]\n",
        "\n",
        "<br/> <br/>\n",
        "Faculty of Information Technology, Monash University, Australia\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqMi8gdDBD1L"
      },
      "source": [
        "# <font color=\"#0b486b\">  Student Information</font>\n",
        "***\n",
        "Surname: **Shin**  <br/>\n",
        "Firstname: **Jiseok**    <br/>\n",
        "Student ID: **[33095310]**    <br/>\n",
        "Email: **[jshi0072@student.monash.edu]**    <br/>\n",
        "Your tutorial time: **[Thursday 2pm-5pm]**    <br/>\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e8EwkVtGva7"
      },
      "source": [
        "# <font color=\"0b486b\">Assignment 2 – Deep Learning for Sequential Data</font>\n",
        "### Due: <font color=\"red\">11:55pm Sunday, 26 October 2025</font> (FIT3181)\n",
        "\n",
        "#### <font color=\"red\">Important note:</font> This is an **individual** assignment. It contributes **20%** to your final mark. Read the assignment instructions carefully."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PF8vqRzTCEsm"
      },
      "source": [
        "## <font color=\"#0b486b\">Assignment 2's Organization</font>\n",
        "This assignment 2 has two (2) sections:\n",
        "- Section 1: Fundamentals of RNNs (10 marks).\n",
        "- Section 2: Deep Learning for Sequential Data (90 marks). This section is further divided into 4 parts.\n",
        "\n",
        "The assignment 2 is organized in three (3) notebooks.\n",
        "- Notebook 1 (this notebook) [Total: 30 marks] includes Section 1 as well as Part 1 and Part 2 of Section 2.\n",
        "- Notebook 2 ([link](https://colab.research.google.com/drive/1m0mh9Mk4-AKEhgAHRwQdl5mc0x7SF7Tv?usp=sharing)) [Total: 40 marks] includes Part 3 of Section 2.\n",
        "- Notebook 3 ([link](https://colab.research.google.com/drive/1JfMZeCkkvjZ5LvKNV-UnR10pl-RogMgF?usp=sharing)) [Total: 30 marks] includes Part 4 of Section 2.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnlGo-hGBvlO"
      },
      "source": [
        "## <font color=\"#0b486b\">What to submit</font>\n",
        "\n",
        "This assignment is to be completed individually and submitted to Moodle unit site. **By the due date, you are required to submit one  <font color=\"red; font-weight:bold\">single zip file, named 33095310_assignment02_solution.zip</font> where `xxx` is your student ID, to the corresponding Assignment (Dropbox) in Moodle**. You can use Google Colab to do Assignment 2 but you need to save it to an `*.ipynb` file to submit to the unit Moodle.\n",
        "\n",
        "**More importantly, if you use Google Colab to do this assignment, you need to first make a copy of this notebook on your Google drive**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVGeGjkzn4RG"
      },
      "source": [
        "***For example, if your student ID is <font color=\"red; font-weight:bold\">12356</font>, then gather all of your assignment solutions to a folder, create a zip file named <font color=\"red; font-weight:bold\">123456_assignment02_solution.zip</font> and submit this file.***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3J6gGAMn44Z"
      },
      "source": [
        "Within this zip folder, you **must** submit the following files <u>for each part</u>:\n",
        "1.\t**`FIT3181_DeepLearning_Assignment2_Official[Main].ipynb`**:  this is your Python notebook solution source file.\n",
        "1.\t**`FIT3181_DeepLearning_Assignment2_Official[Main].html`**: this is the output of your Python notebook solution *exported* in HTML format.\n",
        "1. **`FIT3181_DeepLearning_Assignment2_Official[RNNs].ipynb`**\n",
        "1. **`FIT3181_DeepLearning_Assignment2_Official[RNNs].html`**\n",
        "1. **`FIT3181_DeepLearning_Assignment2_Official[Transformers].ipynb`**\n",
        "1. **`FIT3181_DeepLearning_Assignment2_Official[Transformers].html`**\n",
        "1.\tAny **extra files or folder** needed to complete your assignment (e.g., images used in your answers).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsB3OmMxB4Dh"
      },
      "source": [
        "## Section 1: Fundamentals in RNNs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c83ea5R9nh_y"
      },
      "source": [
        "You need to **manually** implement a multi-timestep Recurrent Neural Network that can take an input as a 3D tensor `[batch_size, seq_len, input_size]` for a classification task.\n",
        "\n",
        "<div style=\"text-align: right\"><font color=\"red\">[Total: 10 marks]</font></div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OzH6RTIjExy2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x1183dae10>"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "torch.set_printoptions(sci_mode=False, precision=4)\n",
        "torch.manual_seed(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKlCx1D3rczS"
      },
      "source": [
        "We declare the relevant variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "C77pPiGBA9IJ"
      },
      "outputs": [],
      "source": [
        "input_size = 5\n",
        "seq_len = 4\n",
        "batch_size = 8\n",
        "hidden_size = 3\n",
        "num_classes = 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A10tCeyKrkUt"
      },
      "source": [
        "We create random inputs (i.e., `inputs`) and random labels (i.e., `random_labels`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybfqj-wBEu0H",
        "outputId": "0387f520-f380-47e0-b7e2-c0107d18d77b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([8, 4, 5])\n",
            "tensor([1, 2, 2, 2, 2, 0, 0, 0])\n"
          ]
        }
      ],
      "source": [
        "inputs = torch.randn(batch_size, seq_len, input_size)\n",
        "random_labels = torch.randint(0, num_classes, (batch_size,))\n",
        "print(inputs.shape)\n",
        "print(random_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7ABTPhyr6wa"
      },
      "source": [
        "(1) In what follows, we need to declare the model parameters, which include the matrices $U$ (``[input_size, hidden_size]``), W (``[hidden_size, hidden_size]``), $V$ (``[hidden_size, num_classes]``) and the biases $b$ and $c$ for the hidden states and logits respectively.\n",
        "\n",
        "<div style=\"text-align: right\"><font color=\"red\">[2 marks]</font></div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "qzlZtACzsbSR"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "U: torch.Size([5, 3]) W: torch.Size([3, 3]) b: torch.Size([3]) V: torch.Size([3, 3]) c: torch.Size([3])\n"
          ]
        }
      ],
      "source": [
        "#Insert your code here\n",
        "U = torch.nn.Parameter(torch.randn(input_size, hidden_size) * (2/hidden_size)**0.5)\n",
        "W = torch.nn.Parameter(torch.randn(hidden_size, hidden_size) * (2/hidden_size)**0.5)\n",
        "b = torch.nn.Parameter(torch.zeros(hidden_size))\n",
        "V = torch.nn.Parameter(torch.randn(hidden_size, num_classes) * (2/hidden_size)**0.5)\n",
        "c = torch.nn.Parameter(torch.zeros(num_classes))\n",
        "\n",
        "\n",
        "params = [U, W, b, V, c]\n",
        "for p in params:\n",
        "    p.requires_grad_(True)\n",
        "    \n",
        "print(\"U:\", U.shape, \"W:\", W.shape, \"b:\", b.shape, \"V:\", V.shape, \"c:\", c.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MW_gal7Us9fK"
      },
      "source": [
        "(2) Next you need to write the code to compute `hiddens` which is a 3D tensor of the shape ``[batch_size, seq_len, hidden_size]`` using the formula of the simple/standard RNN cells. You can freely modify the code below.\n",
        "\n",
        "<div style=\"text-align: right\"><font color=\"red\">[2 marks]</font></div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "KwxqdXkTtaea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([8, 4, 3])\n",
            "tensor([[ 0.9996, -0.9977, -0.9888],\n",
            "        [-0.9293,  0.9716, -0.8190]], grad_fn=<SelectBackward0>)\n"
          ]
        }
      ],
      "source": [
        "#Initialize hiddens for update.\n",
        "hiddens = torch.zeros(batch_size, seq_len, hidden_size)\n",
        "\n",
        "#Insert your code here\n",
        "h_prev = torch.zeros(batch_size, hidden_size)\n",
        "for t in range(seq_len):\n",
        "    x_t = inputs[:, t, :]                               # (batch_size, input_size)\n",
        "    h_t = torch.tanh(x_t @ U + h_prev @ W + b)          # (batch_size, hidden_size)\n",
        "    hiddens[:, t, :] = h_t\n",
        "    h_prev = h_t\n",
        "\n",
        "print(hiddens.shape)\n",
        "print(hiddens[:2, -1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sC3gaFvLtyUW"
      },
      "source": [
        "(3) In what follows, you need to write the code to compute the logits based on the last hidden state (``[batch_size, hidden_size]``) of hiddens.\n",
        "\n",
        "<div style=\"text-align: right\"><font color=\"red\">[1 mark]</font></div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Psr-vrw8uCMN"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "logits.shape: torch.Size([8, 3])\n",
            "tensor([[ 1.3990,  0.2307,  0.7709],\n",
            "        [-1.1064,  0.1209,  0.8236],\n",
            "        [-0.6812, -0.2259,  0.7966],\n",
            "        [-1.2046, -0.2168, -0.7344],\n",
            "        [-1.2082, -0.4272, -0.8664],\n",
            "        [-1.1872, -0.2159, -0.7938],\n",
            "        [-0.2276,  0.2471, -0.3473],\n",
            "        [-1.2993, -0.3404, -0.8288]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ],
      "source": [
        "h_last = hiddens[:, -1, :]\n",
        "logits = h_last @ V + c       \n",
        "print(\"logits.shape:\", logits.shape)\n",
        "print(logits)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DEJQQz9uKFb"
      },
      "source": [
        "(4) Write the code to compute the cross-entropy loss by comparing the logits to the labels. You can use PyTorch's built-in loss function.\n",
        "\n",
        "<div style=\"text-align: right\"><font color=\"red\">[1 mark]</font></div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Gyy7lbacuWPR"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss: 1.206323504447937\n",
            "tensor(1.2063, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ],
      "source": [
        "#Insert your code here\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "loss = criterion(logits, random_labels)\n",
        "print(\"loss:\", loss.item())\n",
        "print(loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVt-977bumET"
      },
      "source": [
        "(5) Next, you need to do back-propagation to compute the gradients of the loss w.r.t. the model parameters. You can use PyTorch's built-in method to compute the gradients.\n",
        "\n",
        "<div style=\"text-align: right\"><font color=\"red\">[2 marks]</font></div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "HSpeFroAu6oO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "U.grad norm: 0.344451\n",
            "W.grad norm: 0.275753\n",
            "b.grad norm: 0.142836\n",
            "V.grad norm: 0.791970\n",
            "c.grad norm: 0.330426\n"
          ]
        }
      ],
      "source": [
        "#Insert your code here\n",
        "\n",
        "# Zero grads (in case this cell is re-run)\n",
        "for p in params:\n",
        "    if p.grad is not None:\n",
        "        p.grad.zero_()\n",
        "\n",
        "# Recompute forward (so graph is intact) and backward\n",
        "h_prev = torch.zeros(batch_size, hidden_size)\n",
        "hiddens = torch.zeros(batch_size, seq_len, hidden_size)\n",
        "for t in range(seq_len):\n",
        "    x_t = inputs[:, t, :]\n",
        "    h_prev = torch.tanh(x_t @ U + h_prev @ W + b)\n",
        "    hiddens[:, t, :] = h_prev\n",
        "\n",
        "h_last = hiddens[:, -1, :]\n",
        "logits = h_last @ V + c\n",
        "loss = criterion(logits, random_labels)\n",
        "loss.backward()\n",
        "\n",
        "for name, p in zip([\"U\",\"W\",\"b\",\"V\",\"c\"], params):\n",
        "    print(f\"{name}.grad norm: {p.grad.norm().item():.6f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEkHFzOovBx1"
      },
      "source": [
        "(6) Finally, let assume that the learning rate $\\eta = 0.1$, you need to write the code to **manually** update the new model parameters using the SGD manner.\n",
        "\n",
        "<div style=\"text-align: right\"><font color=\"red\">[2 marks]</font></div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "2zFSfys8wMqs"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.7968389987945557\n",
            "-0.8018071055412292\n"
          ]
        }
      ],
      "source": [
        "#Insert your code here\n",
        "lr = 0.1\n",
        "\n",
        "#before\n",
        "print(params[0][0, 0].item())\n",
        "\n",
        "with torch.no_grad():\n",
        "    for p in params:\n",
        "        p -= lr * p.grad\n",
        "\n",
        "# Check the same parameter after update\n",
        "print(params[0][0, 0].item())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAVPM0BnTdd4"
      },
      "source": [
        "## Section 2: Deep Learning for Sequential Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FAgUSME4TsCP"
      },
      "source": [
        "### <font color=\"#0b486b\">Set random seeds</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00nhh4IRUcGX"
      },
      "source": [
        "We start with importing PyTorch and NumPy and setting random seeds for PyTorch and NumPy. You can use any seeds you prefer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "O7XWUry0JXCc"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import random\n",
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from transformers import BertTokenizer\n",
        "import os\n",
        "from six.moves.urllib.request import urlretrieve\n",
        "from sklearn import preprocessing\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "6ZoWqunmUY7L"
      },
      "outputs": [],
      "source": [
        "def seed_all(seed=1029):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "seed_all(seed=1234)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VU1jS6SUl8q"
      },
      "source": [
        "## <font color=\"#0b486b\">Download and preprocess the data</font>\n",
        "\n",
        "<div style=\"text-align: right\"><font color=\"red; font-weight:bold\"><span></div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQEzWmZjUulL"
      },
      "source": [
        "The dataset we use for this assignment is a question classification dataset for which the training set consists of $5,500$ questions belonging to 6 coarse question categories including:\n",
        "- abbreviation (ABBR),\n",
        "- entity (ENTY),\n",
        "- description (DESC),\n",
        "- human (HUM),\n",
        "- location (LOC) and\n",
        "- numeric (NUM).\n",
        "\n",
        "In this assignment, we will utilize a subset of this dataset, containing $2,000$ questions for training and validation. We will use 80% of those 2000 questions for trainning and the rest for validation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOd49RTpUxxj"
      },
      "source": [
        "Preprocessing data is a crucial initial step in any machine learning or deep learning project. The *TextDataManager* class simplifies the process by providing functionalities to download and preprocess data specifically designed for the subsequent questions in this assignment. It is highly recommended to gain a comprehensive understanding of the class's functionality by **carefully reading** the content provided in the *TextDataManager* class before proceeding to answer the questions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "_C2fuJNzUhha"
      },
      "outputs": [],
      "source": [
        "class DataManager:\n",
        "    \"\"\"\n",
        "    This class manages and preprocesses a simple text dataset for a sentence classification task.\n",
        "\n",
        "    Attributes:\n",
        "        verbose (bool): Controls verbosity for printing information during data processing.\n",
        "        max_sentence_len (int): The maximum length of a sentence in the dataset.\n",
        "        str_questions (list): A list to store the string representations of the questions in the dataset.\n",
        "        str_labels (list): A list to store the string representations of the labels in the dataset.\n",
        "        numeral_labels (list): A list to store the numerical representations of the labels in the dataset.\n",
        "        numeral_data (list): A list to store the numerical representations of the questions in the dataset.\n",
        "        random_state (int): Seed value for random number generation to ensure reproducibility.\n",
        "            Set this value to a specific integer to reproduce the same random sequence every time. Defaults to 6789.\n",
        "        random (np.random.RandomState): Random number generator object initialized with the given random_state.\n",
        "            It is used for various random operations in the class.\n",
        "\n",
        "    Methods:\n",
        "        maybe_download(dir_name, file_name, url, verbose=True):\n",
        "            Downloads a file from a given URL if it does not exist in the specified directory.\n",
        "            The directory and file are created if they do not exist.\n",
        "\n",
        "        read_data(dir_name, file_names):\n",
        "            Reads data from files in a directory, preprocesses it, and computes the maximum sentence length.\n",
        "            Each file is expected to contain rows in the format \"<label>:<question>\".\n",
        "            The labels and questions are stored as string representations.\n",
        "\n",
        "        manipulate_data():\n",
        "            Performs data manipulation by tokenizing, numericalizing, and padding the text data.\n",
        "            The questions are tokenized and converted into numerical sequences using a tokenizer.\n",
        "            The sequences are padded or truncated to the maximum sequence length.\n",
        "\n",
        "        train_valid_test_split(train_ratio=0.9):\n",
        "            Splits the data into training, validation, and test sets based on a given ratio.\n",
        "            The data is randomly shuffled, and the specified ratio is used to determine the size of the training set.\n",
        "            The string questions, numerical data, and numerical labels are split accordingly.\n",
        "            TensorFlow `Dataset` objects are created for the training and validation sets.\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, verbose=True, random_state=6789):\n",
        "        self.verbose = verbose\n",
        "        self.max_sentence_len = 0\n",
        "        self.str_questions = list()\n",
        "        self.str_labels = list()\n",
        "        self.numeral_labels = list()\n",
        "        self.maxlen = None\n",
        "        self.numeral_data = list()\n",
        "        self.random_state = random_state\n",
        "        self.random = np.random.RandomState(random_state)\n",
        "\n",
        "    @staticmethod\n",
        "    def maybe_download(dir_name, file_name, url, verbose=True):\n",
        "        if not os.path.exists(dir_name):\n",
        "            os.mkdir(dir_name)\n",
        "        if not os.path.exists(os.path.join(dir_name, file_name)):\n",
        "            urlretrieve(url + file_name, os.path.join(dir_name, file_name))\n",
        "        if verbose:\n",
        "            print(\"Downloaded successfully {}\".format(file_name))\n",
        "\n",
        "    def read_data(self, dir_name, file_names):\n",
        "        self.str_questions = list()\n",
        "        self.str_labels = list()\n",
        "        for file_name in file_names:\n",
        "            file_path= os.path.join(dir_name, file_name)\n",
        "            with open(file_path, \"r\", encoding=\"latin-1\") as f:\n",
        "                for row in f:\n",
        "                    row_str = row.split(\":\")\n",
        "                    label, question = row_str[0], row_str[1]\n",
        "                    question = question.lower()\n",
        "                    self.str_labels.append(label)\n",
        "                    self.str_questions.append(question[0:-1])\n",
        "                    if self.max_sentence_len < len(self.str_questions[-1]):\n",
        "                        self.max_sentence_len = len(self.str_questions[-1])\n",
        "\n",
        "        # turns labels into numbers\n",
        "        le = preprocessing.LabelEncoder()\n",
        "        le.fit(self.str_labels)\n",
        "        self.numeral_labels = np.array(le.transform(self.str_labels))\n",
        "        self.str_classes = le.classes_\n",
        "        self.num_classes = len(self.str_classes)\n",
        "        if self.verbose:\n",
        "            print(\"\\nSample questions and corresponding labels... \\n\")\n",
        "            print(self.str_questions[0:5])\n",
        "            print(self.str_labels[0:5])\n",
        "\n",
        "    def manipulate_data(self):\n",
        "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "        vocab = self.tokenizer.get_vocab()\n",
        "        self.word2idx = {w: i for i, w in enumerate(vocab)}\n",
        "        self.idx2word = {i:w for w,i in self.word2idx.items()}\n",
        "        self.vocab_size = len(self.word2idx)\n",
        "\n",
        "        token_ids = []\n",
        "        num_seqs = []\n",
        "        for text in self.str_questions:  # iterate over the list of text\n",
        "          text_seqs = self.tokenizer.tokenize(str(text))  # tokenize each text individually\n",
        "          # Convert tokens to IDs\n",
        "          token_ids = self.tokenizer.convert_tokens_to_ids(text_seqs)\n",
        "          # Convert token IDs to a tensor of indices using your word2idx mapping\n",
        "          seq_tensor = torch.LongTensor(token_ids)\n",
        "          num_seqs.append(seq_tensor)  # append the tensor for each sequence\n",
        "\n",
        "        # Pad the sequences and create a tensor\n",
        "        if num_seqs:\n",
        "          self.numeral_data = pad_sequence(num_seqs, batch_first=True)  # Pads to max length of the sequences\n",
        "          self.num_sentences, self.maxlen = self.numeral_data.shape\n",
        "\n",
        "    def train_valid_test_split(self, train_ratio=0.8, test_ratio = 0.1):\n",
        "        train_size = int(self.num_sentences*train_ratio) +1\n",
        "        test_size = int(self.num_sentences*test_ratio) +1\n",
        "        valid_size = self.num_sentences - (train_size + test_size)\n",
        "        data_indices = list(range(self.num_sentences))\n",
        "        random.shuffle(data_indices)\n",
        "        self.train_str_questions = [self.str_questions[i] for i in data_indices[:train_size]]\n",
        "        self.train_numeral_labels = self.numeral_labels[data_indices[:train_size]]\n",
        "        train_set_data = self.numeral_data[data_indices[:train_size]]\n",
        "        train_set_labels = self.numeral_labels[data_indices[:train_size]]\n",
        "        train_set_labels = torch.from_numpy(train_set_labels)\n",
        "        train_set = torch.utils.data.TensorDataset(train_set_data, train_set_labels)\n",
        "        self.test_str_questions = [self.str_questions[i] for i in data_indices[-test_size:]]\n",
        "        self.test_numeral_labels = self.numeral_labels[data_indices[-test_size:]]\n",
        "        test_set_data = self.numeral_data[data_indices[-test_size:]]\n",
        "        test_set_labels = self.numeral_labels[data_indices[-test_size:]]\n",
        "        test_set_labels = torch.from_numpy(test_set_labels)\n",
        "        test_set = torch.utils.data.TensorDataset(test_set_data, test_set_labels)\n",
        "        self.valid_str_questions = [self.str_questions[i] for i in data_indices[train_size:-test_size]]\n",
        "        self.valid_numeral_labels = self.numeral_labels[data_indices[train_size:-test_size]]\n",
        "        valid_set_data = self.numeral_data[data_indices[train_size:-test_size]]\n",
        "        valid_set_labels = self.numeral_labels[data_indices[train_size:-test_size]]\n",
        "        valid_set_labels = torch.from_numpy(valid_set_labels)\n",
        "        valid_set = torch.utils.data.TensorDataset(valid_set_data, valid_set_labels)\n",
        "        self.train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
        "        self.test_loader = DataLoader(test_set, batch_size=64, shuffle=False)\n",
        "        self.valid_loader = DataLoader(valid_set, batch_size=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3npdESj6Vb_t",
        "outputId": "7822da78-eb83-4989-c737-a75aef97d134"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            "Downloaded successfully train_2000.label\n",
            "\n",
            "Sample questions and corresponding labels... \n",
            "\n",
            "['manner how did serfdom develop in and then leave russia ?', 'cremat what films featured the character popeye doyle ?', \"manner how can i find a list of celebrities ' real names ?\", 'animal what fowl grabs the spotlight after the chinese year of the monkey ?', 'exp what is the full form of .com ?']\n",
            "['DESC', 'ENTY', 'DESC', 'ENTY', 'ABBR']\n"
          ]
        }
      ],
      "source": [
        "print('Loading data...')\n",
        "DataManager.maybe_download(\"data\", \"train_2000.label\", \"http://cogcomp.org/Data/QA/QC/\")\n",
        "\n",
        "dm = DataManager()\n",
        "dm.read_data(\"data/\", [\"train_2000.label\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310,
          "referenced_widgets": [
            "2b5d8a6cfdfe4b1e95449279f82761c3",
            "de01c2173d0e440685eb1ac9b884988f",
            "4e32263423444dc8901f4d23cc2b330d",
            "91e59f5a40fc40d983e35386990324d6",
            "37d50405bf0b4e4680f81c082b2e8840",
            "4943de4fa70944cf89e7ca5adfb8273d",
            "7e8d325cf40240fa9b02ede10425ef4e",
            "4761b8cd787c4e63bc46796aca463292",
            "260d4df916764a05a3ada3064296c23b",
            "0db82c9c23d2441d8953e0a47ca01a6b",
            "c34b8a2216574fedbab6a7a596cbc626",
            "f10cf00b28084470ba4dfba1d8a5996d",
            "a72f9d0d378e4c2e9c465d236210b28b",
            "c4f76fdc51b442788f80ab75d79fd969",
            "b9c39c7dff8d4a74a1b7c4f2a686f8c1",
            "c4ae7881130f4e199782e7cc5eb8d8a0",
            "7c9283ea1d5349829123ef15d32aee58",
            "240ea606f4c2434b88965d5a222e4051",
            "2ee0fb07a3974a9cb150fb3accf13c5d",
            "50486104aed747bebdf05efb8a039b7b",
            "37b55f5eea464a77ae5744b86fd294f1",
            "1d3acfbcd78b41e4bd648089e271ed9d",
            "74ac7c2dfc1f4868932a4542b4488604",
            "41cfa051ce84475fbd822b1b1e9ceda4",
            "1f4e711b1e5c480db1261ba94de9efba",
            "a50640383277495291b29f090f4e6b42",
            "8da1e203b84d49f08564f1f2f5fff662",
            "226ea735f94f4ec1bc3e84c98230c170",
            "bf6ee7481825400288abd9abc8585e91",
            "2770be23025f4d5c990b581a171b3160",
            "d17c96976faa4bf2b1b6eac10bb7fc61",
            "dd081a5b24b0459fbb0499041ca6078e",
            "61e6a3b02d574088afee41257a6e72f0",
            "7ae77f5e5f5e4906bc793f3e40edf881",
            "87e8f90800084eab9da3d5abbb8731b8",
            "5aa6842e49594cb98382d9c1639e6f4e",
            "45665a851e7f425bbaf07666f397d97d",
            "dad255bf2c19468ebb366d512e791192",
            "26020e573f5f4503b9030a046ba25d98",
            "502c1c79d2f348eb868194ec493cd110",
            "86f6064c5e174041a5088431df791154",
            "4ab2a6c9c7da44a981cd26448e125c19",
            "df14ee10fe6c44a7a7cd6ba44ce50704",
            "5ab79ed067c0474f95f89938f97a92cf"
          ]
        },
        "id": "EgrYZPmyVj60",
        "outputId": "3609ecf0-4154-4aa4-954d-aee636096ade"
      },
      "outputs": [],
      "source": [
        "dm.manipulate_data()\n",
        "dm.train_valid_test_split(train_ratio=0.8, test_ratio = 0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bH-U0sUMVnW-",
        "outputId": "6b3e6b8f-4064-4c9f-d4c0-69d59c109ae0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([64, 36]) torch.Size([64])\n"
          ]
        }
      ],
      "source": [
        "for x, y in dm.train_loader:\n",
        "    print(x.shape, y.shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frFf7-ehVvNM"
      },
      "source": [
        "## <font color=\"#0b486b\">Part 1: Using Word2Vect to transform texts to vectors </font>\n",
        "\n",
        "<div style=\"text-align: right\"><font color=\"red; font-weight:bold\">[Total marks for this part: 10 marks]<span></div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "KZFrETlMVq7P"
      },
      "outputs": [],
      "source": [
        "import gensim.downloader as api\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JH-f1BJY9bw"
      },
      "source": [
        "#### <font color=\"red\">**Question 1.1**</font>\n",
        "**Write code to download the pretrained model *glove-wiki-gigaword-100*. Note that this model transforms a word in its dictionary to a $100$ dimensional vector.**\n",
        "\n",
        "**Write code for the function *get_word_vector(word, model)* used to transform a word to a vector using the pretrained Word2Vect model *model*. Note that for a word not in the vocabulary of our *word2vect*, you need to return a vector $0$ with 100 dimensions.**\n",
        "\n",
        "<div style=\"text-align: right\"><font color=\"red\">[2 marks]</font></div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b76lh_hZVyac",
        "outputId": "0cd87611-e3db-4e51-c336-9e1b084317f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[==================================================] 100.0% 128.1/128.1MB downloaded\n"
          ]
        }
      ],
      "source": [
        "word2vect = api.load(\"glove-wiki-gigaword-100\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "GpbibKfdZB-S"
      },
      "outputs": [],
      "source": [
        "def get_word_vector(word, model):\n",
        "    try:\n",
        "        vector = model.get_vector(word)\n",
        "    except:\n",
        "        vector = np.zeros(model.vector_size, dtype=np.float32)\n",
        "    return vector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TjRdyTg2_dN"
      },
      "source": [
        "#### <font color=\"red\">**Question 1.2**</font>\n",
        "\n",
        "**Write the code for the function `get_sentence_vector(sentence, important_score=None, model= None)`. Note that this function will transform a sentence to a 100-dimensional vector using the pretrained model *model*. In addition, the list *important_score* which has the same length as the *sentence* specifies the important scores of the words in the sentence. In your code, you first need to apply *softmax* function over *important_score* to obtain the important weight *important_weight* which forms a probability over the words of the sentence. Furthermore, the final vector of the sentence will be weighted sum of the individual vectors for words and the weights in *important_weight*.**\n",
        "- $important\\_weight = softmax(important\\_score)$.\n",
        "- $final\\_vector= important\\_weight[1]\\times v[1] + important\\_weight[2]\\times v[2] + ...+ important\\_weight[T]\\times v[T]$ where $T$ is the length of the sentence and $v[i]$ is the vector representation of the $i-th$  word in this sentence.\n",
        "\n",
        "**Note that if `important_score=None` is set by default, your function should return the average of all representation vectors corresponding to set `important_score=[1,1,...,1]`.**\n",
        "\n",
        "<div style=\"text-align: right\"><font color=\"red\">[2 marks]</font></div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "MaPs4Hqa2_30"
      },
      "outputs": [],
      "source": [
        "\n",
        "def _softmax(x):\n",
        "    x = np.asarray(x, dtype=np.float32)\n",
        "    x -= x.max()                      # numerical stability\n",
        "    ex = np.exp(x)\n",
        "    return ex / (ex.sum() + 1e-12)\n",
        "\n",
        "#If important_score is None, use a uniform average. If provided, softmax the scores and take a weighted sum.\n",
        "def get_sentence_vector(sentence, important_score=None, model=None):\n",
        "    \"\"\"important_score: list/array (len = #tokens). If None -> uniform average.\n",
        "    model: pretrained KeyedVectors (e.g., GloVe).\n",
        "    \"\"\"\n",
        "    assert model is not None, \"Please pass the pretrained model\"\n",
        "\n",
        "    # very simple tokenization (assignment usually expects this)\n",
        "    tokens = sentence.strip().lower().split()\n",
        "    if len(tokens) == 0:\n",
        "        return np.zeros(model.vector_size, dtype=np.float32)\n",
        "\n",
        "    # collect word vectors (OOV -> zeros)\n",
        "    vecs = np.stack([get_word_vector(w, model) for w in tokens], axis=0)  # [T, D]\n",
        "\n",
        "    if important_score is None:\n",
        "        # uniform average\n",
        "        feature_vector = vecs.mean(axis=0)\n",
        "    else:\n",
        "        # softmax -> weights sum to 1\n",
        "        weights = _softmax(important_score)           # [T]\n",
        "        feature_vector = (weights[:, None] * vecs).sum(axis=0)\n",
        "\n",
        "    return feature_vector.astype(np.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tu63GJ2c3IgZ"
      },
      "source": [
        "#### <font color=\"red\">**Question 1.3**</font>\n",
        "\n",
        "**Write code to transform questions in *dm.train_str_questions* and *dm.valid_str_questions* to feature vectors. Note that after running the following cells, you must have $X\\_train$ and $X\\_valid$ which are two NumPy arrays of the feature vectors and $y\\_train$ and $y\\_valid$ which are two arrays of numeric labels (Hint: *dm.train_numeral_labels* and *dm.valid_numeral_labels*). You can add more lines to the following cells if necessary. In addition, you should decide the *important_score* by yourself. For example, the 1st score is 1, the 2nd score is decayed by 0.9, the 3rd is decayed by 0.9, and so on.**\n",
        "\n",
        "<div style=\"text-align: right\"><font color=\"red\">[2 marks]</font></div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def decayed_importance(n_tokens, gamma=0.9):\n",
        "    return np.power(gamma, np.arange(n_tokens, dtype=np.float32)) # [1, gamma, gamma^2, ...]  → any length T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SCsWIdZ3I4S",
        "outputId": "4691df38-1e88-47cf-c392-378a0086dfc5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transform training set to feature vectors...\n"
          ]
        }
      ],
      "source": [
        "print(\"Transform training set to feature vectors...\")\n",
        "X_train = []\n",
        "y_train = dm.train_numeral_labels\n",
        "for s in dm.train_str_questions:\n",
        "    T = max(1, len(s.strip().split()))\n",
        "    imp = decayed_importance(T, gamma=0.9)\n",
        "    x = get_sentence_vector(s, important_score=imp, model=word2vect)\n",
        "    X_train.append(x)\n",
        "X_train = np.stack(X_train, axis=0).astype(np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2odznptZ3Nf_",
        "outputId": "d007af2d-bbef-436a-ee62-7940a83fdf5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transform validation set to feature vectors...\n"
          ]
        }
      ],
      "source": [
        "print(\"Transform validation set to feature vectors...\")\n",
        "X_valid = []\n",
        "y_valid = dm.valid_numeral_labels\n",
        "for s in dm.valid_str_questions:\n",
        "    T = max(1, len(s.strip().split()))\n",
        "    imp = decayed_importance(T, gamma=0.9)\n",
        "    x = get_sentence_vector(s, important_score=imp, model=word2vect)\n",
        "    X_valid.append(x)\n",
        "X_valid = np.stack(X_valid, axis=0).astype(np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shapes → X_train: (1601, 100)  y_train: (1601,) | X_valid: (198, 100)  y_valid: (198,)\n"
          ]
        }
      ],
      "source": [
        "print(\"Shapes → X_train:\", X_train.shape, \" y_train:\", y_train.shape,\n",
        "      \"| X_valid:\", X_valid.shape, \" y_valid:\", y_valid.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOp_gy3d3Reh"
      },
      "source": [
        "#### <font color=\"red\">**Question 1.4**</font>\n",
        "\n",
        "**It is now to use *MinMaxScaler(feature_range=(-1,1))* in scikit-learn to scale both training and validation sets to the range $(-1,1)$.**\n",
        "\n",
        "<div style=\"text-align: right\"><font color=\"red\">[2 marks]</font></div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eT47Q13c3VJV",
        "outputId": "9320ccc2-263b-4fb6-ec6e-19cc52a0a800"
      },
      "outputs": [],
      "source": [
        "#Insert your code\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcvKQyHO3ZJx"
      },
      "source": [
        "#### <font color=\"red\">**Question 1.5**</font>\n",
        "**Train a Logistic Regression model on the training set and then evaluate on the validation set.** You can use any classification metrics in `sklearn` for evaluation.\n",
        "<div style=\"text-align: right\"><font color=\"red\">[2 marks]</font></div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IQYE_rz-3b25"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "#Insert your code\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ucJWNHMO3gXF"
      },
      "outputs": [],
      "source": [
        "from sklearn import metrics\n",
        "#Insert your code\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZs9Y0rl7gBH"
      },
      "source": [
        "We now declare the `BaseTrainer` class, which will be used later to train the subsequent deep learning models for text data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yXlNQvGn7OEb"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class BaseTrainer:\n",
        "    def __init__(self, model, criterion, optimizer, train_loader, val_loader):\n",
        "        self.model = model\n",
        "        self.criterion = criterion  #the loss function\n",
        "        self.optimizer = optimizer  #the optimizer\n",
        "        self.train_loader = train_loader  #the train loader\n",
        "        self.val_loader = val_loader  #the valid loader\n",
        "\n",
        "    #the function to train the model in many epochs\n",
        "    def fit(self, num_epochs):\n",
        "        self.num_batches = len(self.train_loader)\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            print(f'Epoch {epoch + 1}/{num_epochs}')\n",
        "            train_loss, train_accuracy = self.train_one_epoch()\n",
        "            val_loss, val_accuracy = self.validate_one_epoch()\n",
        "            print(\n",
        "                f'{self.num_batches}/{self.num_batches} - train_loss: {train_loss:.4f} - train_accuracy: {train_accuracy*100:.4f}% \\\n",
        "                - val_loss: {val_loss:.4f} - val_accuracy: {val_accuracy*100:.4f}%')\n",
        "\n",
        "    #train in one epoch, return the train_acc, train_loss\n",
        "    def train_one_epoch(self):\n",
        "        self.model.train()\n",
        "        running_loss, correct, total = 0.0, 0, 0\n",
        "        for i, data in enumerate(self.train_loader):\n",
        "            inputs, labels = data\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            self.optimizer.zero_grad()\n",
        "            outputs = self.model(inputs)\n",
        "            loss = self.criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "        train_accuracy = correct / total\n",
        "        train_loss = running_loss / self.num_batches\n",
        "        return train_loss, train_accuracy\n",
        "\n",
        "    #evaluate on a loader and return the loss and accuracy\n",
        "    def evaluate(self, loader):\n",
        "        self.model.eval()\n",
        "        loss, correct, total = 0.0, 0, 0\n",
        "        with torch.no_grad():\n",
        "            for data in loader:\n",
        "                inputs, labels = data\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = self.model(inputs)\n",
        "                loss = self.criterion(outputs, labels)\n",
        "                loss += loss.item()\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        accuracy = correct / total\n",
        "        loss = loss / len(self.val_loader)\n",
        "        return loss, accuracy\n",
        "\n",
        "    #return the val_acc, val_loss, be called at the end of each epoch\n",
        "    def validate_one_epoch(self):\n",
        "      val_loss, val_accuracy = self.evaluate(self.val_loader)\n",
        "      return val_loss, val_accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GWOQN_S7p4V"
      },
      "source": [
        "## <font color=\"#0b486b\">Part 2: Text CNN for sequence modeling and neural embedding </font>\n",
        "\n",
        "<div style=\"text-align: right\"><font color=\"red; font-weight:bold\">[Total marks for this part: 10 marks]<span></div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJub3Fwm7vC7"
      },
      "source": [
        "**In what follows, you are required to complete the code for Text CNN for sentence classification. The paper of Text CNN can be found at this [link](https://www.aclweb.org/anthology/D14-1181.pdf). Here is the description of the Text CNN that you need to construct.**\n",
        "- There are three attributes (properties or instance variables): *embed_size, state_size, data_manager*.\n",
        "  - `embed_size`: the dimension of the vector space for which the words are embedded to using the embedding matrix.\n",
        "  - `state_size`: the number of filters used in *Conv1D* (reference [here](https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html)).\n",
        "  - `data_manager`: the data manager to store information of the dataset.\n",
        "- The detail of the computational process is as follows:\n",
        "  - Given input $x$, we embed $x$ using the embedding matrix to obtain an $3D$ tensor $[batch\\_size, seq\\_len, embed\\_size]$ as $e$.\n",
        "  - We feed $e$ to three *Conv1D* layers, each of which has $state\\_size$ filters, activation= $relu$, and $kernel\\_size= 3, 5, 7$ respectively to obtain $h1, h2, h3$. Note that each $h1, h2, h3$ is a 3D tensor with the shape $[batch\\_size, state\\_size, output\\_size]$. Moreover, you need to apply *Conv1D* to the $seq\\_len$ dimension.\n",
        "  - We then apply *GlobalMaxPool1D()* (reference [here](https://pytorch.org/docs/stable/generated/torch.nn.functional.max_pool1d.html#torch.nn.functional.max_pool1d)) over $h1, h2, h3$ to obtain 2D tensors stored in $h1, h2, h3$ again.\n",
        "  - We then concatenate three 2D tensors $h1, h2, h3$ to obtain $h$ with the shape $\\left[batch\\_size, 3\\times state\\_size\\right]$. Note that you need to specify the axis to concatenate.\n",
        "  - We finally build up one dense layer $\\left[3\\times state\\_size, num\\_classes\\right]$  on the top of $h$ for classification.\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lEnG-BGJ239k"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "#You can modify the code if you want but need to keep the skeleton\n",
        "class TextCNN(torch.nn.Module):\n",
        "    def __init__(self, embed_size= 128, state_size=16, data_manager=None):\n",
        "        super().__init__()\n",
        "        self.data_manager = data_manager\n",
        "        self.embed_size = embed_size\n",
        "        self.state_size = state_size\n",
        "        #declare the necessary layers here\n",
        "        self.embed = nn.Embedding(self.data_manager.vocab_size, self.embed_size)\n",
        "        self.conv1d_1 = # Insert your code here\n",
        "        self.conv1d_2 = # Insert your code here\n",
        "        self.conv1d_3 = # Insert your code here\n",
        "        self.fc = nn.Linear(state_size*3, self.data_manager.num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        e = self.embed(x)\n",
        "        #permute x before applying Conv1D\n",
        "        e= e.permute(0,2,1)\n",
        "\n",
        "        #applying Conv1D\n",
        "        h1 = # Insert your code here\n",
        "        h2 = # Insert your code here\n",
        "        h3 = # Insert your code here\n",
        "\n",
        "        #apply GlobalMaxPool\n",
        "        h1 = # Insert your code here\n",
        "        h2 = # Insert your code here\n",
        "        h3 = # Insert your code here\n",
        "\n",
        "        h =  # Insert your code here\n",
        "        h = self.fc(h)\n",
        "        return h"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-PN6KmIFw6K"
      },
      "source": [
        "We declare `text_cnn` and train on several epochs (e.g., `50 epochs`).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IrL5oM82BR3_",
        "outputId": "494f66d3-98b3-4768-8d82-46e32f1134aa"
      },
      "outputs": [],
      "source": [
        "text_cnn = TextCNN(data_manager=dm).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(text_cnn.parameters(), lr=0.001)\n",
        "trainer = BaseTrainer(model=text_cnn, criterion=criterion, optimizer=optimizer, train_loader=dm.train_loader, val_loader=dm.valid_loader)\n",
        "trainer.fit(num_epochs=50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrjO5iT6F_Li"
      },
      "source": [
        "We evaluate the trained model on the testing set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnHiWCl7BtJC",
        "outputId": "ba7b7eba-d589-4b2e-fd10-57b7127ca61f"
      },
      "outputs": [],
      "source": [
        "test_loss, test_acc = trainer.evaluate(dm.test_loader)\n",
        "print(f'test_loss: {test_loss:.4f} - test_accuracy: {test_acc*100:.4f}%')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "nlp",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0db82c9c23d2441d8953e0a47ca01a6b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d3acfbcd78b41e4bd648089e271ed9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f4e711b1e5c480db1261ba94de9efba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2770be23025f4d5c990b581a171b3160",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d17c96976faa4bf2b1b6eac10bb7fc61",
            "value": 466062
          }
        },
        "226ea735f94f4ec1bc3e84c98230c170": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "240ea606f4c2434b88965d5a222e4051": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "26020e573f5f4503b9030a046ba25d98": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "260d4df916764a05a3ada3064296c23b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2770be23025f4d5c990b581a171b3160": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b5d8a6cfdfe4b1e95449279f82761c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_de01c2173d0e440685eb1ac9b884988f",
              "IPY_MODEL_4e32263423444dc8901f4d23cc2b330d",
              "IPY_MODEL_91e59f5a40fc40d983e35386990324d6"
            ],
            "layout": "IPY_MODEL_37d50405bf0b4e4680f81c082b2e8840"
          }
        },
        "2ee0fb07a3974a9cb150fb3accf13c5d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37b55f5eea464a77ae5744b86fd294f1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37d50405bf0b4e4680f81c082b2e8840": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41cfa051ce84475fbd822b1b1e9ceda4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_226ea735f94f4ec1bc3e84c98230c170",
            "placeholder": "​",
            "style": "IPY_MODEL_bf6ee7481825400288abd9abc8585e91",
            "value": "tokenizer.json: 100%"
          }
        },
        "45665a851e7f425bbaf07666f397d97d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df14ee10fe6c44a7a7cd6ba44ce50704",
            "placeholder": "​",
            "style": "IPY_MODEL_5ab79ed067c0474f95f89938f97a92cf",
            "value": " 570/570 [00:00&lt;00:00, 20.8kB/s]"
          }
        },
        "4761b8cd787c4e63bc46796aca463292": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4943de4fa70944cf89e7ca5adfb8273d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ab2a6c9c7da44a981cd26448e125c19": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4e32263423444dc8901f4d23cc2b330d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4761b8cd787c4e63bc46796aca463292",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_260d4df916764a05a3ada3064296c23b",
            "value": 48
          }
        },
        "502c1c79d2f348eb868194ec493cd110": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "50486104aed747bebdf05efb8a039b7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5aa6842e49594cb98382d9c1639e6f4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86f6064c5e174041a5088431df791154",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4ab2a6c9c7da44a981cd26448e125c19",
            "value": 570
          }
        },
        "5ab79ed067c0474f95f89938f97a92cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "61e6a3b02d574088afee41257a6e72f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "74ac7c2dfc1f4868932a4542b4488604": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_41cfa051ce84475fbd822b1b1e9ceda4",
              "IPY_MODEL_1f4e711b1e5c480db1261ba94de9efba",
              "IPY_MODEL_a50640383277495291b29f090f4e6b42"
            ],
            "layout": "IPY_MODEL_8da1e203b84d49f08564f1f2f5fff662"
          }
        },
        "7ae77f5e5f5e4906bc793f3e40edf881": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_87e8f90800084eab9da3d5abbb8731b8",
              "IPY_MODEL_5aa6842e49594cb98382d9c1639e6f4e",
              "IPY_MODEL_45665a851e7f425bbaf07666f397d97d"
            ],
            "layout": "IPY_MODEL_dad255bf2c19468ebb366d512e791192"
          }
        },
        "7c9283ea1d5349829123ef15d32aee58": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e8d325cf40240fa9b02ede10425ef4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "86f6064c5e174041a5088431df791154": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87e8f90800084eab9da3d5abbb8731b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26020e573f5f4503b9030a046ba25d98",
            "placeholder": "​",
            "style": "IPY_MODEL_502c1c79d2f348eb868194ec493cd110",
            "value": "config.json: 100%"
          }
        },
        "8da1e203b84d49f08564f1f2f5fff662": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91e59f5a40fc40d983e35386990324d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0db82c9c23d2441d8953e0a47ca01a6b",
            "placeholder": "​",
            "style": "IPY_MODEL_c34b8a2216574fedbab6a7a596cbc626",
            "value": " 48.0/48.0 [00:00&lt;00:00, 3.06kB/s]"
          }
        },
        "a50640383277495291b29f090f4e6b42": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd081a5b24b0459fbb0499041ca6078e",
            "placeholder": "​",
            "style": "IPY_MODEL_61e6a3b02d574088afee41257a6e72f0",
            "value": " 466k/466k [00:00&lt;00:00, 13.2MB/s]"
          }
        },
        "a72f9d0d378e4c2e9c465d236210b28b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c9283ea1d5349829123ef15d32aee58",
            "placeholder": "​",
            "style": "IPY_MODEL_240ea606f4c2434b88965d5a222e4051",
            "value": "vocab.txt: 100%"
          }
        },
        "b9c39c7dff8d4a74a1b7c4f2a686f8c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37b55f5eea464a77ae5744b86fd294f1",
            "placeholder": "​",
            "style": "IPY_MODEL_1d3acfbcd78b41e4bd648089e271ed9d",
            "value": " 232k/232k [00:00&lt;00:00, 10.9MB/s]"
          }
        },
        "bf6ee7481825400288abd9abc8585e91": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c34b8a2216574fedbab6a7a596cbc626": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c4ae7881130f4e199782e7cc5eb8d8a0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4f76fdc51b442788f80ab75d79fd969": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ee0fb07a3974a9cb150fb3accf13c5d",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_50486104aed747bebdf05efb8a039b7b",
            "value": 231508
          }
        },
        "d17c96976faa4bf2b1b6eac10bb7fc61": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dad255bf2c19468ebb366d512e791192": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd081a5b24b0459fbb0499041ca6078e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de01c2173d0e440685eb1ac9b884988f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4943de4fa70944cf89e7ca5adfb8273d",
            "placeholder": "​",
            "style": "IPY_MODEL_7e8d325cf40240fa9b02ede10425ef4e",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "df14ee10fe6c44a7a7cd6ba44ce50704": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f10cf00b28084470ba4dfba1d8a5996d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a72f9d0d378e4c2e9c465d236210b28b",
              "IPY_MODEL_c4f76fdc51b442788f80ab75d79fd969",
              "IPY_MODEL_b9c39c7dff8d4a74a1b7c4f2a686f8c1"
            ],
            "layout": "IPY_MODEL_c4ae7881130f4e199782e7cc5eb8d8a0"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
